//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21112126
// Cuda compilation tools, release 8.0, V8.0.43
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_20
.address_size 64

	// .globl	_Z17pinhole_camera_msv
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0
)
;
.global .align 8 .b8 eye[12];
.global .align 4 .b8 U[12];
.global .align 4 .b8 V[12];
.global .align 4 .b8 W[12];
.global .align 4 .f32 fov;
.global .align 16 .b8 diffuse[16];
.global .align 4 .u32 texCount;
.global .align 16 .b8 lightDir[16];
.global .align 16 .b8 lightPos[16];
.global .align 4 .u32 frameCount;
.global .align 4 .u32 trace;
.global .align 8 .b8 top_object[4];
.global .align 1 .b8 vertex_buffer[1];
.global .align 1 .b8 index_buffer[1];
.global .align 1 .b8 normal[1];
.global .align 1 .b8 texCoord0[1];
.global .texref tex0;
.global .align 1 .b8 output0[1];
.global .align 4 .b8 ray[36];
.global .align 8 .b8 launch_index[8];
.global .align 8 .b8 launch_dim[8];
.global .align 16 .b8 prdr[32];
.global .align 4 .f32 t_hit;
.global .align 8 .b8 texCoord[12];
.global .align 8 .b8 geometric_normal[12];
.global .align 8 .b8 shading_normal[12];
.global .align 4 .u32 Phong;
.global .align 4 .u32 Shadow;
.global .align 8 .u64 _ZN21rti_internal_register20reg_bitness_detectorE;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail0E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail1E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail2E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail3E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail4E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail5E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail6E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail7E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail8E;
.global .align 8 .u64 _ZN21rti_internal_register24reg_exception_64_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail0E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail1E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail2E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail3E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail4E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail5E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail6E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail7E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail8E;
.global .align 4 .u32 _ZN21rti_internal_register21reg_exception_detail9E;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_xE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_yE;
.global .align 4 .u32 _ZN21rti_internal_register14reg_rayIndex_zE;
.global .align 4 .b8 _ZN21rti_internal_typeinfo3eyeE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1UE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1VE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo1WE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3fovE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo7diffuseE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8texCountE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8lightDirE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8lightPosE[8] = {82, 97, 121, 0, 16, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10frameCountE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5traceE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10top_objectE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo3rayE[8] = {82, 97, 121, 0, 36, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo12launch_indexE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo10launch_dimE[8] = {82, 97, 121, 0, 8, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo4prdrE[8] = {82, 97, 121, 0, 32, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5t_hitE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo8texCoordE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo16geometric_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo14shading_normalE[8] = {82, 97, 121, 0, 12, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo5PhongE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 4 .b8 _ZN21rti_internal_typeinfo6ShadowE[8] = {82, 97, 121, 0, 4, 0, 0, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3eyeE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1UE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1VE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename1WE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3fovE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename7diffuseE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8texCountE[4] = {105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8lightDirE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8lightPosE[7] = {102, 108, 111, 97, 116, 52, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10frameCountE[5] = {117, 105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5traceE[4] = {105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10top_objectE[9] = {114, 116, 79, 98, 106, 101, 99, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename3rayE[11] = {111, 112, 116, 105, 120, 58, 58, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_typename12launch_indexE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename10launch_dimE[6] = {117, 105, 110, 116, 50, 0};
.global .align 1 .b8 _ZN21rti_internal_typename4prdrE[17] = {80, 101, 114, 82, 97, 121, 68, 97, 116, 97, 82, 101, 115, 117, 108, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5t_hitE[6] = {102, 108, 111, 97, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename8texCoordE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename16geometric_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename14shading_normalE[7] = {102, 108, 111, 97, 116, 51, 0};
.global .align 1 .b8 _ZN21rti_internal_typename5PhongE[4] = {105, 110, 116, 0};
.global .align 1 .b8 _ZN21rti_internal_typename6ShadowE[4] = {105, 110, 116, 0};
.global .align 4 .u32 _ZN21rti_internal_typeenum3eyeE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1UE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1VE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum1WE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3fovE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum7diffuseE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8texCountE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8lightDirE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8lightPosE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10frameCountE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5traceE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10top_objectE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum3rayE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum12launch_indexE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum10launch_dimE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum4prdrE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5t_hitE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum8texCoordE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum16geometric_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum14shading_normalE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum5PhongE = 4919;
.global .align 4 .u32 _ZN21rti_internal_typeenum6ShadowE = 4919;
.global .align 1 .b8 _ZN21rti_internal_semantic3eyeE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1UE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1VE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic1WE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3fovE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic7diffuseE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8texCountE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8lightDirE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic8lightPosE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic10frameCountE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic5traceE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic10top_objectE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic3rayE[13] = {114, 116, 67, 117, 114, 114, 101, 110, 116, 82, 97, 121, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic12launch_indexE[14] = {114, 116, 76, 97, 117, 110, 99, 104, 73, 110, 100, 101, 120, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic10launch_dimE[12] = {114, 116, 76, 97, 117, 110, 99, 104, 68, 105, 109, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic4prdrE[10] = {114, 116, 80, 97, 121, 108, 111, 97, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic5t_hitE[23] = {114, 116, 73, 110, 116, 101, 114, 115, 101, 99, 116, 105, 111, 110, 68, 105, 115, 116, 97, 110, 99, 101, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic8texCoordE[19] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 116, 101, 120, 99, 111, 111, 114, 100, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic16geometric_normalE[27] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 103, 101, 111, 109, 101, 116, 114, 105, 99, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic14shading_normalE[25] = {97, 116, 116, 114, 105, 98, 117, 116, 101, 32, 115, 104, 97, 100, 105, 110, 103, 95, 110, 111, 114, 109, 97, 108, 0};
.global .align 1 .b8 _ZN21rti_internal_semantic5PhongE[1];
.global .align 1 .b8 _ZN21rti_internal_semantic6ShadowE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3eyeE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1UE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1VE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation1WE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3fovE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation7diffuseE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8texCountE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8lightDirE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8lightPosE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10frameCountE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5traceE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10top_objectE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation3rayE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation12launch_indexE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation10launch_dimE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation4prdrE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5t_hitE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation8texCoordE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation16geometric_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation14shading_normalE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation5PhongE[1];
.global .align 1 .b8 _ZN23rti_internal_annotation6ShadowE[1];

.visible .entry _Z17pinhole_camera_msv(

)
{
	.local .align 16 .b8 	__local_depot0[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .f32 	%f<255>;
	.reg .b32 	%r<292>;
	.reg .b64 	%rd<23>;


	mov.u64 	%rd22, __local_depot0;
	cvta.local.u64 	%SP, %rd22;
	add.u64 	%rd9, %SP, 0;
	cvta.to.local.u64 	%rd16, %rd9;
	mov.u64 	%rd17, output0;
	cvta.global.u64 	%rd5, %rd17;
	mov.u32 	%r15, 2;
	mov.u32 	%r16, 16;
	// inline asm
	call (%rd1, %rd2, %rd3, %rd4), _rt_buffer_get_size_64, (%rd5, %r15, %r16);
	// inline asm
	cvt.rn.f32.u64	%f33, %rd1;
	cvt.rn.f32.u64	%f34, %rd2;
	rcp.approx.ftz.f32 	%f35, %f33;
	rcp.approx.ftz.f32 	%f36, %f34;
	add.ftz.f32 	%f37, %f35, %f35;
	add.ftz.f32 	%f38, %f36, %f36;
	ld.global.v2.u32 	{%r17, %r18}, [launch_index];
	cvt.rn.f32.u32	%f39, %r17;
	cvt.rn.f32.u32	%f40, %r18;
	fma.rn.ftz.f32 	%f41, %f37, %f39, 0fBF800000;
	fma.rn.ftz.f32 	%f42, %f38, %f40, 0fBF800000;
	mul.ftz.f32 	%f43, %f37, 0f3F000000;
	mul.ftz.f32 	%f44, %f38, 0f3F000000;
	cvt.u64.u32	%rd18, %r18;
	mul.lo.s64 	%rd19, %rd18, %rd1;
	cvt.u64.u32	%rd20, %r17;
	add.s64 	%rd21, %rd19, %rd20;
	cvt.u32.u64	%r21, %rd21;
	ld.global.u32 	%r22, [frameCount];
	shl.b32 	%r23, %r22, 4;
	add.s32 	%r24, %r23, -1556008596;
	add.s32 	%r25, %r22, -1640531527;
	shr.u32 	%r26, %r22, 5;
	add.s32 	%r27, %r26, -939442524;
	xor.b32  	%r28, %r24, %r25;
	xor.b32  	%r29, %r28, %r27;
	add.s32 	%r30, %r29, %r21;
	shl.b32 	%r31, %r30, 4;
	add.s32 	%r32, %r31, -1383041155;
	add.s32 	%r33, %r30, -1640531527;
	xor.b32  	%r34, %r32, %r33;
	shr.u32 	%r35, %r30, 5;
	add.s32 	%r36, %r35, 2123724318;
	xor.b32  	%r37, %r34, %r36;
	add.s32 	%r38, %r37, %r22;
	shl.b32 	%r39, %r38, 4;
	add.s32 	%r40, %r39, -1556008596;
	add.s32 	%r41, %r38, 1013904242;
	shr.u32 	%r42, %r38, 5;
	add.s32 	%r43, %r42, -939442524;
	xor.b32  	%r44, %r40, %r41;
	xor.b32  	%r45, %r44, %r43;
	add.s32 	%r46, %r45, %r30;
	shl.b32 	%r47, %r46, 4;
	add.s32 	%r48, %r47, -1383041155;
	add.s32 	%r49, %r46, 1013904242;
	xor.b32  	%r50, %r48, %r49;
	shr.u32 	%r51, %r46, 5;
	add.s32 	%r52, %r51, 2123724318;
	xor.b32  	%r53, %r50, %r52;
	add.s32 	%r54, %r53, %r38;
	shl.b32 	%r55, %r54, 4;
	add.s32 	%r56, %r55, -1556008596;
	add.s32 	%r57, %r54, -626627285;
	shr.u32 	%r58, %r54, 5;
	add.s32 	%r59, %r58, -939442524;
	xor.b32  	%r60, %r56, %r57;
	xor.b32  	%r61, %r60, %r59;
	add.s32 	%r62, %r61, %r46;
	shl.b32 	%r63, %r62, 4;
	add.s32 	%r64, %r63, -1383041155;
	add.s32 	%r65, %r62, -626627285;
	xor.b32  	%r66, %r64, %r65;
	shr.u32 	%r67, %r62, 5;
	add.s32 	%r68, %r67, 2123724318;
	xor.b32  	%r69, %r66, %r68;
	add.s32 	%r70, %r69, %r54;
	shl.b32 	%r71, %r70, 4;
	add.s32 	%r72, %r71, -1556008596;
	add.s32 	%r73, %r70, 2027808484;
	shr.u32 	%r74, %r70, 5;
	add.s32 	%r75, %r74, -939442524;
	xor.b32  	%r76, %r72, %r73;
	xor.b32  	%r77, %r76, %r75;
	add.s32 	%r78, %r77, %r62;
	shl.b32 	%r79, %r78, 4;
	add.s32 	%r80, %r79, -1383041155;
	add.s32 	%r81, %r78, 2027808484;
	xor.b32  	%r82, %r80, %r81;
	shr.u32 	%r83, %r78, 5;
	add.s32 	%r84, %r83, 2123724318;
	xor.b32  	%r85, %r82, %r84;
	add.s32 	%r86, %r85, %r70;
	shl.b32 	%r87, %r86, 4;
	add.s32 	%r88, %r87, -1556008596;
	add.s32 	%r89, %r86, 387276957;
	shr.u32 	%r90, %r86, 5;
	add.s32 	%r91, %r90, -939442524;
	xor.b32  	%r92, %r88, %r89;
	xor.b32  	%r93, %r92, %r91;
	add.s32 	%r94, %r93, %r78;
	shl.b32 	%r95, %r94, 4;
	add.s32 	%r96, %r95, -1383041155;
	add.s32 	%r97, %r94, 387276957;
	xor.b32  	%r98, %r96, %r97;
	shr.u32 	%r99, %r94, 5;
	add.s32 	%r100, %r99, 2123724318;
	xor.b32  	%r101, %r98, %r100;
	add.s32 	%r102, %r101, %r86;
	shl.b32 	%r103, %r102, 4;
	add.s32 	%r104, %r103, -1556008596;
	add.s32 	%r105, %r102, -1253254570;
	shr.u32 	%r106, %r102, 5;
	add.s32 	%r107, %r106, -939442524;
	xor.b32  	%r108, %r104, %r105;
	xor.b32  	%r109, %r108, %r107;
	add.s32 	%r110, %r109, %r94;
	shl.b32 	%r111, %r110, 4;
	add.s32 	%r112, %r111, -1383041155;
	add.s32 	%r113, %r110, -1253254570;
	xor.b32  	%r114, %r112, %r113;
	shr.u32 	%r115, %r110, 5;
	add.s32 	%r116, %r115, 2123724318;
	xor.b32  	%r117, %r114, %r116;
	add.s32 	%r118, %r117, %r102;
	shl.b32 	%r119, %r118, 4;
	add.s32 	%r120, %r119, -1556008596;
	add.s32 	%r121, %r118, 1401181199;
	shr.u32 	%r122, %r118, 5;
	add.s32 	%r123, %r122, -939442524;
	xor.b32  	%r124, %r120, %r121;
	xor.b32  	%r125, %r124, %r123;
	add.s32 	%r126, %r125, %r110;
	shl.b32 	%r127, %r126, 4;
	add.s32 	%r128, %r127, -1383041155;
	add.s32 	%r129, %r126, 1401181199;
	xor.b32  	%r130, %r128, %r129;
	shr.u32 	%r131, %r126, 5;
	add.s32 	%r132, %r131, 2123724318;
	xor.b32  	%r133, %r130, %r132;
	add.s32 	%r134, %r133, %r118;
	shl.b32 	%r135, %r134, 4;
	add.s32 	%r136, %r135, -1556008596;
	add.s32 	%r137, %r134, -239350328;
	shr.u32 	%r138, %r134, 5;
	add.s32 	%r139, %r138, -939442524;
	xor.b32  	%r140, %r136, %r137;
	xor.b32  	%r141, %r140, %r139;
	add.s32 	%r142, %r141, %r126;
	shl.b32 	%r143, %r142, 4;
	add.s32 	%r144, %r143, -1383041155;
	add.s32 	%r145, %r142, -239350328;
	xor.b32  	%r146, %r144, %r145;
	shr.u32 	%r147, %r142, 5;
	add.s32 	%r148, %r147, 2123724318;
	xor.b32  	%r149, %r146, %r148;
	add.s32 	%r150, %r149, %r134;
	shl.b32 	%r151, %r150, 4;
	add.s32 	%r152, %r151, -1556008596;
	add.s32 	%r153, %r150, -1879881855;
	shr.u32 	%r154, %r150, 5;
	add.s32 	%r155, %r154, -939442524;
	xor.b32  	%r156, %r152, %r153;
	xor.b32  	%r157, %r156, %r155;
	add.s32 	%r158, %r157, %r142;
	shl.b32 	%r159, %r158, 4;
	add.s32 	%r160, %r159, -1383041155;
	add.s32 	%r161, %r158, -1879881855;
	xor.b32  	%r162, %r160, %r161;
	shr.u32 	%r163, %r158, 5;
	add.s32 	%r164, %r163, 2123724318;
	xor.b32  	%r165, %r162, %r164;
	add.s32 	%r166, %r165, %r150;
	shl.b32 	%r167, %r166, 4;
	add.s32 	%r168, %r167, -1556008596;
	add.s32 	%r169, %r166, 774553914;
	shr.u32 	%r170, %r166, 5;
	add.s32 	%r171, %r170, -939442524;
	xor.b32  	%r172, %r168, %r169;
	xor.b32  	%r173, %r172, %r171;
	add.s32 	%r174, %r173, %r158;
	shl.b32 	%r175, %r174, 4;
	add.s32 	%r176, %r175, -1383041155;
	add.s32 	%r177, %r174, 774553914;
	xor.b32  	%r178, %r176, %r177;
	shr.u32 	%r179, %r174, 5;
	add.s32 	%r180, %r179, 2123724318;
	xor.b32  	%r181, %r178, %r180;
	add.s32 	%r182, %r181, %r166;
	shl.b32 	%r183, %r182, 4;
	add.s32 	%r184, %r183, -1556008596;
	add.s32 	%r185, %r182, -865977613;
	shr.u32 	%r186, %r182, 5;
	add.s32 	%r187, %r186, -939442524;
	xor.b32  	%r188, %r184, %r185;
	xor.b32  	%r189, %r188, %r187;
	add.s32 	%r190, %r189, %r174;
	shl.b32 	%r191, %r190, 4;
	add.s32 	%r192, %r191, -1383041155;
	add.s32 	%r193, %r190, -865977613;
	xor.b32  	%r194, %r192, %r193;
	shr.u32 	%r195, %r190, 5;
	add.s32 	%r196, %r195, 2123724318;
	xor.b32  	%r197, %r194, %r196;
	add.s32 	%r198, %r197, %r182;
	shl.b32 	%r199, %r198, 4;
	add.s32 	%r200, %r199, -1556008596;
	add.s32 	%r201, %r198, 1788458156;
	shr.u32 	%r202, %r198, 5;
	add.s32 	%r203, %r202, -939442524;
	xor.b32  	%r204, %r200, %r201;
	xor.b32  	%r205, %r204, %r203;
	add.s32 	%r206, %r205, %r190;
	shl.b32 	%r207, %r206, 4;
	add.s32 	%r208, %r207, -1383041155;
	add.s32 	%r209, %r206, 1788458156;
	xor.b32  	%r210, %r208, %r209;
	shr.u32 	%r211, %r206, 5;
	add.s32 	%r212, %r211, 2123724318;
	xor.b32  	%r213, %r210, %r212;
	add.s32 	%r214, %r213, %r198;
	shl.b32 	%r215, %r214, 4;
	add.s32 	%r216, %r215, -1556008596;
	add.s32 	%r217, %r214, 147926629;
	shr.u32 	%r218, %r214, 5;
	add.s32 	%r219, %r218, -939442524;
	xor.b32  	%r220, %r216, %r217;
	xor.b32  	%r221, %r220, %r219;
	add.s32 	%r222, %r221, %r206;
	shl.b32 	%r223, %r222, 4;
	add.s32 	%r224, %r223, -1383041155;
	add.s32 	%r225, %r222, 147926629;
	xor.b32  	%r226, %r224, %r225;
	shr.u32 	%r227, %r222, 5;
	add.s32 	%r228, %r227, 2123724318;
	xor.b32  	%r229, %r226, %r228;
	add.s32 	%r230, %r229, %r214;
	shl.b32 	%r231, %r230, 4;
	add.s32 	%r232, %r231, -1556008596;
	add.s32 	%r233, %r230, -1492604898;
	shr.u32 	%r234, %r230, 5;
	add.s32 	%r235, %r234, -939442524;
	xor.b32  	%r236, %r232, %r233;
	xor.b32  	%r237, %r236, %r235;
	add.s32 	%r238, %r237, %r222;
	shl.b32 	%r239, %r238, 4;
	add.s32 	%r240, %r239, -1383041155;
	add.s32 	%r241, %r238, -1492604898;
	xor.b32  	%r242, %r240, %r241;
	shr.u32 	%r243, %r238, 5;
	add.s32 	%r244, %r243, 2123724318;
	xor.b32  	%r245, %r242, %r244;
	add.s32 	%r246, %r245, %r230;
	shl.b32 	%r247, %r246, 4;
	add.s32 	%r248, %r247, -1556008596;
	add.s32 	%r249, %r246, 1161830871;
	shr.u32 	%r250, %r246, 5;
	add.s32 	%r251, %r250, -939442524;
	xor.b32  	%r252, %r248, %r249;
	xor.b32  	%r253, %r252, %r251;
	add.s32 	%r254, %r253, %r238;
	shl.b32 	%r255, %r254, 4;
	add.s32 	%r256, %r255, -1383041155;
	add.s32 	%r257, %r254, 1161830871;
	xor.b32  	%r258, %r256, %r257;
	shr.u32 	%r259, %r254, 5;
	add.s32 	%r260, %r259, 2123724318;
	xor.b32  	%r261, %r258, %r260;
	add.s32 	%r262, %r261, %r246;
	shl.b32 	%r263, %r262, 4;
	add.s32 	%r264, %r263, -1556008596;
	add.s32 	%r265, %r262, -478700656;
	shr.u32 	%r266, %r262, 5;
	add.s32 	%r267, %r266, -939442524;
	xor.b32  	%r268, %r264, %r265;
	xor.b32  	%r269, %r268, %r267;
	add.s32 	%r270, %r269, %r254;
	mad.lo.s32 	%r271, %r270, 1664525, 1013904223;
	and.b32  	%r272, %r271, 16777215;
	cvt.rn.f32.u32	%f45, %r272;
	mov.f32 	%f46, 0f4B800000;
	div.approx.ftz.f32 	%f47, %f45, %f46;
	add.ftz.f32 	%f48, %f47, 0f3F800000;
	mad.lo.s32 	%r273, %r271, 1664525, 1013904223;
	and.b32  	%r274, %r273, 16777215;
	cvt.rn.f32.u32	%f49, %r274;
	div.approx.ftz.f32 	%f50, %f49, %f46;
	add.ftz.f32 	%f51, %f50, 0f3F800000;
	fma.rn.ftz.f32 	%f52, %f43, %f48, %f41;
	fma.rn.ftz.f32 	%f53, %f44, %f51, %f42;
	ld.global.v2.f32 	{%f54, %f55}, [eye];
	ld.global.f32 	%f3, [eye+8];
	ld.global.f32 	%f56, [U];
	mul.ftz.f32 	%f57, %f56, %f52;
	ld.global.f32 	%f58, [U+4];
	mul.ftz.f32 	%f59, %f52, %f58;
	ld.global.f32 	%f60, [U+8];
	mul.ftz.f32 	%f61, %f52, %f60;
	ld.global.f32 	%f62, [fov];
	ld.global.f32 	%f63, [V];
	mul.ftz.f32 	%f64, %f53, %f63;
	ld.global.f32 	%f65, [V+4];
	mul.ftz.f32 	%f66, %f53, %f65;
	ld.global.f32 	%f67, [V+8];
	mul.ftz.f32 	%f68, %f53, %f67;
	mul.ftz.f32 	%f69, %f64, %f62;
	mul.ftz.f32 	%f70, %f66, %f62;
	mul.ftz.f32 	%f71, %f68, %f62;
	fma.rn.ftz.f32 	%f72, %f57, %f62, %f69;
	fma.rn.ftz.f32 	%f73, %f59, %f62, %f70;
	fma.rn.ftz.f32 	%f74, %f61, %f62, %f71;
	ld.global.f32 	%f75, [W];
	add.ftz.f32 	%f76, %f75, %f72;
	ld.global.f32 	%f77, [W+4];
	add.ftz.f32 	%f78, %f73, %f77;
	ld.global.f32 	%f79, [W+8];
	add.ftz.f32 	%f80, %f74, %f79;
	mul.ftz.f32 	%f81, %f78, %f78;
	fma.rn.ftz.f32 	%f82, %f76, %f76, %f81;
	fma.rn.ftz.f32 	%f83, %f80, %f80, %f82;
	rsqrt.approx.ftz.f32 	%f84, %f83;
	mul.ftz.f32 	%f4, %f76, %f84;
	mul.ftz.f32 	%f5, %f78, %f84;
	mul.ftz.f32 	%f6, %f80, %f84;
	ld.global.u32 	%r4, [Phong];
	mov.f32 	%f85, 0f3F800000;
	st.local.v4.f32 	[%rd16], {%f85, %f85, %f85, %f85};
	mov.u32 	%r275, 0;
	st.local.v2.u32 	[%rd16+16], {%r275, %r273};
	ld.global.u32 	%r3, [top_object];
	mov.f32 	%f31, 0f3089705F;
	mov.f32 	%f32, 0f6C4ECB8F;
	mov.u32 	%r14, 32;
	// inline asm
	call _rt_trace_64, (%r3, %f54, %f55, %f3, %f4, %f5, %f6, %r4, %f31, %f32, %rd9, %r14);
	// inline asm
	ld.local.v4.f32 	{%f86, %f87, %f88, %f89}, [%rd16];
	add.ftz.f32 	%f91, %f86, 0f00000000;
	add.ftz.f32 	%f93, %f87, 0f00000000;
	add.ftz.f32 	%f95, %f88, 0f00000000;
	add.ftz.f32 	%f97, %f89, 0f00000000;
	mad.lo.s32 	%r276, %r273, 1664525, 1013904223;
	and.b32  	%r277, %r276, 16777215;
	cvt.rn.f32.u32	%f98, %r277;
	div.approx.ftz.f32 	%f99, %f98, %f46;
	add.ftz.f32 	%f100, %f99, 0f3F800000;
	mad.lo.s32 	%r278, %r276, 1664525, 1013904223;
	and.b32  	%r279, %r278, 16777215;
	cvt.rn.f32.u32	%f101, %r279;
	div.approx.ftz.f32 	%f102, %f101, %f46;
	add.ftz.f32 	%f103, %f102, 0f40000000;
	fma.rn.ftz.f32 	%f104, %f43, %f100, %f41;
	fma.rn.ftz.f32 	%f105, %f44, %f103, %f42;
	ld.global.v2.f32 	{%f106, %f107}, [eye];
	ld.global.f32 	%f11, [eye+8];
	ld.global.f32 	%f108, [U];
	mul.ftz.f32 	%f109, %f108, %f104;
	ld.global.f32 	%f110, [U+4];
	mul.ftz.f32 	%f111, %f104, %f110;
	ld.global.f32 	%f112, [U+8];
	mul.ftz.f32 	%f113, %f104, %f112;
	ld.global.f32 	%f114, [fov];
	ld.global.f32 	%f115, [V];
	mul.ftz.f32 	%f116, %f105, %f115;
	ld.global.f32 	%f117, [V+4];
	mul.ftz.f32 	%f118, %f105, %f117;
	ld.global.f32 	%f119, [V+8];
	mul.ftz.f32 	%f120, %f105, %f119;
	mul.ftz.f32 	%f121, %f116, %f114;
	mul.ftz.f32 	%f122, %f118, %f114;
	mul.ftz.f32 	%f123, %f120, %f114;
	fma.rn.ftz.f32 	%f124, %f109, %f114, %f121;
	fma.rn.ftz.f32 	%f125, %f111, %f114, %f122;
	fma.rn.ftz.f32 	%f126, %f113, %f114, %f123;
	ld.global.f32 	%f127, [W];
	add.ftz.f32 	%f128, %f127, %f124;
	ld.global.f32 	%f129, [W+4];
	add.ftz.f32 	%f130, %f125, %f129;
	ld.global.f32 	%f131, [W+8];
	add.ftz.f32 	%f132, %f126, %f131;
	mul.ftz.f32 	%f133, %f130, %f130;
	fma.rn.ftz.f32 	%f134, %f128, %f128, %f133;
	fma.rn.ftz.f32 	%f135, %f132, %f132, %f134;
	rsqrt.approx.ftz.f32 	%f136, %f135;
	mul.ftz.f32 	%f12, %f128, %f136;
	mul.ftz.f32 	%f13, %f130, %f136;
	mul.ftz.f32 	%f14, %f132, %f136;
	ld.global.u32 	%r7, [Phong];
	st.local.v4.f32 	[%rd16], {%f85, %f85, %f85, %f85};
	st.local.v2.u32 	[%rd16+16], {%r275, %r278};
	ld.global.u32 	%r6, [top_object];
	// inline asm
	call _rt_trace_64, (%r6, %f106, %f107, %f11, %f12, %f13, %f14, %r7, %f31, %f32, %rd9, %r14);
	// inline asm
	ld.local.v4.f32 	{%f137, %f138, %f139, %f140}, [%rd16];
	add.ftz.f32 	%f142, %f91, %f137;
	add.ftz.f32 	%f144, %f93, %f138;
	add.ftz.f32 	%f146, %f95, %f139;
	add.ftz.f32 	%f148, %f97, %f140;
	mad.lo.s32 	%r280, %r278, 1664525, 1013904223;
	and.b32  	%r281, %r280, 16777215;
	cvt.rn.f32.u32	%f149, %r281;
	div.approx.ftz.f32 	%f150, %f149, %f46;
	add.ftz.f32 	%f151, %f150, 0f40000000;
	mad.lo.s32 	%r282, %r280, 1664525, 1013904223;
	and.b32  	%r283, %r282, 16777215;
	cvt.rn.f32.u32	%f152, %r283;
	div.approx.ftz.f32 	%f153, %f152, %f46;
	add.ftz.f32 	%f154, %f153, 0f3F800000;
	fma.rn.ftz.f32 	%f155, %f43, %f151, %f41;
	fma.rn.ftz.f32 	%f156, %f44, %f154, %f42;
	ld.global.v2.f32 	{%f157, %f158}, [eye];
	ld.global.f32 	%f19, [eye+8];
	ld.global.f32 	%f159, [U];
	mul.ftz.f32 	%f160, %f159, %f155;
	ld.global.f32 	%f161, [U+4];
	mul.ftz.f32 	%f162, %f155, %f161;
	ld.global.f32 	%f163, [U+8];
	mul.ftz.f32 	%f164, %f155, %f163;
	ld.global.f32 	%f165, [fov];
	ld.global.f32 	%f166, [V];
	mul.ftz.f32 	%f167, %f156, %f166;
	ld.global.f32 	%f168, [V+4];
	mul.ftz.f32 	%f169, %f156, %f168;
	ld.global.f32 	%f170, [V+8];
	mul.ftz.f32 	%f171, %f156, %f170;
	mul.ftz.f32 	%f172, %f167, %f165;
	mul.ftz.f32 	%f173, %f169, %f165;
	mul.ftz.f32 	%f174, %f171, %f165;
	fma.rn.ftz.f32 	%f175, %f160, %f165, %f172;
	fma.rn.ftz.f32 	%f176, %f162, %f165, %f173;
	fma.rn.ftz.f32 	%f177, %f164, %f165, %f174;
	ld.global.f32 	%f178, [W];
	add.ftz.f32 	%f179, %f178, %f175;
	ld.global.f32 	%f180, [W+4];
	add.ftz.f32 	%f181, %f176, %f180;
	ld.global.f32 	%f182, [W+8];
	add.ftz.f32 	%f183, %f177, %f182;
	mul.ftz.f32 	%f184, %f181, %f181;
	fma.rn.ftz.f32 	%f185, %f179, %f179, %f184;
	fma.rn.ftz.f32 	%f186, %f183, %f183, %f185;
	rsqrt.approx.ftz.f32 	%f187, %f186;
	mul.ftz.f32 	%f20, %f179, %f187;
	mul.ftz.f32 	%f21, %f181, %f187;
	mul.ftz.f32 	%f22, %f183, %f187;
	ld.global.u32 	%r10, [Phong];
	st.local.v4.f32 	[%rd16], {%f85, %f85, %f85, %f85};
	st.local.v2.u32 	[%rd16+16], {%r275, %r282};
	ld.global.u32 	%r9, [top_object];
	// inline asm
	call _rt_trace_64, (%r9, %f157, %f158, %f19, %f20, %f21, %f22, %r10, %f31, %f32, %rd9, %r14);
	// inline asm
	ld.local.v4.f32 	{%f188, %f189, %f190, %f191}, [%rd16];
	add.ftz.f32 	%f193, %f142, %f188;
	add.ftz.f32 	%f195, %f144, %f189;
	add.ftz.f32 	%f197, %f146, %f190;
	add.ftz.f32 	%f199, %f148, %f191;
	mad.lo.s32 	%r284, %r282, 1664525, 1013904223;
	and.b32  	%r285, %r284, 16777215;
	cvt.rn.f32.u32	%f200, %r285;
	div.approx.ftz.f32 	%f201, %f200, %f46;
	add.ftz.f32 	%f202, %f201, 0f40000000;
	mad.lo.s32 	%r286, %r284, 1664525, 1013904223;
	and.b32  	%r287, %r286, 16777215;
	cvt.rn.f32.u32	%f203, %r287;
	div.approx.ftz.f32 	%f204, %f203, %f46;
	add.ftz.f32 	%f205, %f204, 0f40000000;
	fma.rn.ftz.f32 	%f206, %f43, %f202, %f41;
	fma.rn.ftz.f32 	%f207, %f44, %f205, %f42;
	ld.global.v2.f32 	{%f208, %f209}, [eye];
	ld.global.f32 	%f27, [eye+8];
	ld.global.f32 	%f210, [U];
	mul.ftz.f32 	%f211, %f210, %f206;
	ld.global.f32 	%f212, [U+4];
	mul.ftz.f32 	%f213, %f206, %f212;
	ld.global.f32 	%f214, [U+8];
	mul.ftz.f32 	%f215, %f206, %f214;
	ld.global.f32 	%f216, [fov];
	ld.global.f32 	%f217, [V];
	mul.ftz.f32 	%f218, %f207, %f217;
	ld.global.f32 	%f219, [V+4];
	mul.ftz.f32 	%f220, %f207, %f219;
	ld.global.f32 	%f221, [V+8];
	mul.ftz.f32 	%f222, %f207, %f221;
	mul.ftz.f32 	%f223, %f218, %f216;
	mul.ftz.f32 	%f224, %f220, %f216;
	mul.ftz.f32 	%f225, %f222, %f216;
	fma.rn.ftz.f32 	%f226, %f211, %f216, %f223;
	fma.rn.ftz.f32 	%f227, %f213, %f216, %f224;
	fma.rn.ftz.f32 	%f228, %f215, %f216, %f225;
	ld.global.f32 	%f229, [W];
	add.ftz.f32 	%f230, %f229, %f226;
	ld.global.f32 	%f231, [W+4];
	add.ftz.f32 	%f232, %f227, %f231;
	ld.global.f32 	%f233, [W+8];
	add.ftz.f32 	%f234, %f228, %f233;
	mul.ftz.f32 	%f235, %f232, %f232;
	fma.rn.ftz.f32 	%f236, %f230, %f230, %f235;
	fma.rn.ftz.f32 	%f237, %f234, %f234, %f236;
	rsqrt.approx.ftz.f32 	%f238, %f237;
	mul.ftz.f32 	%f28, %f230, %f238;
	mul.ftz.f32 	%f29, %f232, %f238;
	mul.ftz.f32 	%f30, %f234, %f238;
	ld.global.u32 	%r13, [Phong];
	st.local.v4.f32 	[%rd16], {%f85, %f85, %f85, %f85};
	st.local.v2.u32 	[%rd16+16], {%r275, %r286};
	ld.global.u32 	%r12, [top_object];
	// inline asm
	call _rt_trace_64, (%r12, %f208, %f209, %f27, %f28, %f29, %f30, %r13, %f31, %f32, %rd9, %r14);
	// inline asm
	ld.local.v4.f32 	{%f239, %f240, %f241, %f242}, [%rd16];
	add.ftz.f32 	%f244, %f193, %f239;
	add.ftz.f32 	%f246, %f195, %f240;
	add.ftz.f32 	%f248, %f197, %f241;
	add.ftz.f32 	%f250, %f199, %f242;
	ld.global.v2.u32 	{%r288, %r289}, [launch_index];
	cvt.u64.u32	%rd12, %r288;
	cvt.u64.u32	%rd13, %r289;
	mov.u64 	%rd15, 0;
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd5, %r15, %r16, %rd12, %rd13, %rd15, %rd15);
	// inline asm
	mul.ftz.f32 	%f251, %f250, 0f3E800000;
	mul.ftz.f32 	%f252, %f248, 0f3E800000;
	mul.ftz.f32 	%f253, %f246, 0f3E800000;
	mul.ftz.f32 	%f254, %f244, 0f3E800000;
	st.v4.f32 	[%rd10], {%f254, %f253, %f252, %f251};
	ret;
}

	// .globl	_Z14any_hit_shadowv
.visible .entry _Z14any_hit_shadowv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	// inline asm
	call _rt_terminate_ray, ();
	// inline asm
	ret;
}

	// .globl	_Z10missShadowv
.visible .entry _Z10missShadowv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f3F800000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z15keepGoingShadowv
.visible .entry _Z15keepGoingShadowv(

)
{
	.reg .pred 	%p<17>;
	.reg .f32 	%f<58>;
	.reg .b32 	%r<37>;
	.reg .f64 	%fd<61>;
	.reg .b64 	%rd<7>;


	mov.u64 	%rd1, shading_normal;
	ldu.global.v2.f32 	{%f17, %f18}, [shading_normal];
	add.s64 	%rd2, %rd1, 8;
	ldu.global.f32 	%f15, [%rd2];
	mov.u32 	%r6, 7937;
	mov.f32 	%f16, 0f00000000;
	// inline asm
	call (%f9, %f10, %f11, %f12), _rt_transform_tuple, (%r6, %f17, %f18, %f15, %f16);
	// inline asm
	mul.ftz.f32 	%f19, %f10, %f10;
	fma.rn.ftz.f32 	%f20, %f9, %f9, %f19;
	fma.rn.ftz.f32 	%f21, %f11, %f11, %f20;
	rsqrt.approx.ftz.f32 	%f22, %f21;
	mul.ftz.f32 	%f1, %f9, %f22;
	mul.ftz.f32 	%f2, %f10, %f22;
	mul.ftz.f32 	%f3, %f11, %f22;
	ld.global.f32 	%f4, [prdr+24];
	setp.eq.ftz.f32	%p2, %f4, 0f00000000;
	@%p2 bra 	BB3_15;
	bra.uni 	BB3_1;

BB3_15:
	ld.global.f32 	%f37, [ray+12];
	ld.global.f32 	%f38, [ray+16];
	mul.ftz.f32 	%f39, %f2, %f38;
	fma.rn.ftz.f32 	%f40, %f1, %f37, %f39;
	ld.global.f32 	%f41, [ray+20];
	fma.rn.ftz.f32 	%f42, %f3, %f41, %f40;
	abs.ftz.f32 	%f43, %f42;
	sqrt.approx.ftz.f32 	%f57, %f43;
	ld.global.f32 	%f44, [t_hit];
	st.global.f32 	[prdr+24], %f44;
	bra.uni 	BB3_16;

BB3_1:
	ld.global.f32 	%f23, [t_hit];
	sub.ftz.f32 	%f24, %f23, %f4;
	abs.ftz.f32 	%f25, %f24;
	cvt.ftz.f64.f32	%fd16, %f25;
	mul.f64 	%fd1, %fd16, 0dBFC6513637DDE829;
	mov.f64 	%fd17, 0d4338000000000000;
	mov.f64 	%fd18, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd19, %fd1, %fd18, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd19;
	}
	mov.f64 	%fd20, 0dC338000000000000;
	add.rn.f64 	%fd21, %fd19, %fd20;
	mov.f64 	%fd22, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd23, %fd21, %fd22, %fd1;
	mov.f64 	%fd24, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd25, %fd21, %fd24, %fd23;
	mov.f64 	%fd26, 0d3E928AF3FCA213EA;
	mov.f64 	%fd27, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd28, %fd27, %fd25, %fd26;
	mov.f64 	%fd29, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd30, %fd28, %fd25, %fd29;
	mov.f64 	%fd31, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd32, %fd30, %fd25, %fd31;
	mov.f64 	%fd33, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd34, %fd32, %fd25, %fd33;
	mov.f64 	%fd35, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd36, %fd34, %fd25, %fd35;
	mov.f64 	%fd37, 0d3F81111111122322;
	fma.rn.f64 	%fd38, %fd36, %fd25, %fd37;
	mov.f64 	%fd39, 0d3FA55555555502A1;
	fma.rn.f64 	%fd40, %fd38, %fd25, %fd39;
	mov.f64 	%fd41, 0d3FC5555555555511;
	fma.rn.f64 	%fd42, %fd40, %fd25, %fd41;
	mov.f64 	%fd43, 0d3FE000000000000B;
	fma.rn.f64 	%fd44, %fd42, %fd25, %fd43;
	mov.f64 	%fd45, 0d3FF0000000000000;
	fma.rn.f64 	%fd46, %fd44, %fd25, %fd45;
	fma.rn.f64 	%fd47, %fd46, %fd25, %fd45;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd47;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd47;
	}
	shl.b32 	%r7, %r1, 20;
	add.s32 	%r8, %r3, %r7;
	mov.b64 	%fd54, {%r2, %r8};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r9}, %fd1;
	}
	mov.b32 	 %f26, %r9;
	abs.ftz.f32 	%f5, %f26;
	setp.lt.ftz.f32	%p3, %f5, 0f4086232B;
	@%p3 bra 	BB3_4;

	setp.lt.f64	%p4, %fd1, 0d0000000000000000;
	add.f64 	%fd48, %fd1, 0d7FF0000000000000;
	selp.f64	%fd54, 0d0000000000000000, %fd48, %p4;
	setp.geu.ftz.f32	%p5, %f5, 0f40874800;
	@%p5 bra 	BB3_4;

	shr.u32 	%r10, %r1, 31;
	add.s32 	%r11, %r1, %r10;
	shr.s32 	%r12, %r11, 1;
	shl.b32 	%r13, %r12, 20;
	add.s32 	%r14, %r13, %r3;
	mov.b64 	%fd49, {%r2, %r14};
	sub.s32 	%r15, %r1, %r12;
	shl.b32 	%r16, %r15, 20;
	add.s32 	%r17, %r16, 1072693248;
	mov.u32 	%r18, 0;
	mov.b64 	%fd50, {%r18, %r17};
	mul.f64 	%fd54, %fd49, %fd50;

BB3_4:
	mov.f64 	%fd51, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r4}, %fd51;
	}
	bfe.u32 	%r19, %r4, 20, 11;
	add.s32 	%r20, %r19, -1012;
	mov.u64 	%rd3, 4616189618054758400;
	shl.b64 	%rd4, %rd3, %r20;
	setp.eq.s64	%p6, %rd4, -9223372036854775808;
	abs.f64 	%fd6, %fd54;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd6;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64	%fd60, [retval0+0];
	
	//{
	}// Callseq End 0
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd54;
	}
	setp.lt.s32	%p7, %r5, 0;
	and.pred  	%p1, %p7, %p6;
	@!%p1 bra 	BB3_6;
	bra.uni 	BB3_5;

BB3_5:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r21}, %fd60;
	}
	xor.b32  	%r22, %r21, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r23, %temp}, %fd60;
	}
	mov.b64 	%fd60, {%r23, %r22};

BB3_6:
	mov.f64 	%fd59, %fd60;
	setp.eq.f64	%p8, %fd54, 0d0000000000000000;
	@%p8 bra 	BB3_9;
	bra.uni 	BB3_7;

BB3_9:
	bfe.u32 	%r24, %r4, 20, 11;
	add.s32 	%r25, %r24, -1012;
	shl.b64 	%rd6, %rd3, %r25;
	setp.eq.s64	%p11, %rd6, -9223372036854775808;
	selp.b32	%r26, %r5, 0, %p11;
	or.b32  	%r27, %r26, 2146435072;
	setp.lt.s32	%p12, %r4, 0;
	selp.b32	%r28, %r27, %r26, %p12;
	mov.u32 	%r29, 0;
	mov.b64 	%fd59, {%r29, %r28};
	bra.uni 	BB3_10;

BB3_7:
	setp.gt.s32	%p9, %r5, -1;
	@%p9 bra 	BB3_10;

	cvt.rzi.f64.f64	%fd53, %fd51;
	setp.neu.f64	%p10, %fd53, 0d4010000000000000;
	selp.f64	%fd59, 0dFFF8000000000000, %fd59, %p10;

BB3_10:
	mov.f64 	%fd12, %fd59;
	add.f64 	%fd13, %fd54, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r30}, %fd13;
	}
	and.b32  	%r31, %r30, 2146435072;
	setp.ne.s32	%p13, %r31, 2146435072;
	mov.f64 	%fd58, %fd12;
	@%p13 bra 	BB3_14;

	setp.gtu.f64	%p14, %fd6, 0d7FF0000000000000;
	mov.f64 	%fd58, %fd13;
	@%p14 bra 	BB3_14;

	setp.neu.f64	%p15, %fd6, 0d7FF0000000000000;
	mov.f64 	%fd58, %fd12;
	@%p15 bra 	BB3_14;

	shr.s32 	%r32, %r4, 31;
	and.b32  	%r33, %r32, -2146435072;
	selp.b32	%r34, -1048576, 2146435072, %p1;
	add.s32 	%r35, %r34, %r33;
	mov.u32 	%r36, 0;
	mov.b64 	%fd58, {%r36, %r35};

BB3_14:
	cvt.rn.ftz.f32.f64	%f27, %fd58;
	setp.eq.f64	%p16, %fd54, 0d3FF0000000000000;
	selp.f32	%f28, 0f3F800000, %f27, %p16;
	ld.global.f32 	%f29, [ray+12];
	ld.global.f32 	%f30, [ray+16];
	mul.ftz.f32 	%f31, %f2, %f30;
	fma.rn.ftz.f32 	%f32, %f1, %f29, %f31;
	ld.global.f32 	%f33, [ray+20];
	fma.rn.ftz.f32 	%f34, %f3, %f33, %f32;
	abs.ftz.f32 	%f35, %f34;
	sqrt.approx.ftz.f32 	%f36, %f35;
	mul.ftz.f32 	%f57, %f28, %f36;

BB3_16:
	ld.global.v4.f32 	{%f45, %f46, %f47, %f48}, [prdr];
	mul.ftz.f32 	%f50, %f57, %f48;
	mul.ftz.f32 	%f52, %f57, %f47;
	mul.ftz.f32 	%f54, %f57, %f46;
	mul.ftz.f32 	%f56, %f57, %f45;
	st.global.v4.f32 	[prdr], {%f56, %f54, %f52, %f50};
	// inline asm
	call _rt_ignore_intersection, ();
	// inline asm
	ret;
}

	// .globl	_Z14tracePathMetalv
.visible .entry _Z14tracePathMetalv(

)
{
	.local .align 16 .b8 	__local_depot4[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<2>;
	.reg .f32 	%f<52>;
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<8>;


	mov.u64 	%rd7, __local_depot4;
	cvta.local.u64 	%SP, %rd7;
	mov.u64 	%rd1, prdr;
	add.s64 	%rd2, %rd1, 16;
	ldu.global.u32 	%r1, [%rd2];
	setp.lt.s32	%p1, %r1, 4;
	@%p1 bra 	BB4_2;
	bra.uni 	BB4_1;

BB4_2:
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	mov.u64 	%rd5, shading_normal;
	ldu.global.v2.f32 	{%f18, %f19}, [shading_normal];
	add.s64 	%rd6, %rd5, 8;
	ldu.global.f32 	%f8, [%rd6];
	mov.u32 	%r2, 7937;
	mov.f32 	%f9, 0f00000000;
	// inline asm
	call (%f2, %f3, %f4, %f5), _rt_transform_tuple, (%r2, %f18, %f19, %f8, %f9);
	// inline asm
	mul.ftz.f32 	%f20, %f3, %f3;
	fma.rn.ftz.f32 	%f21, %f2, %f2, %f20;
	fma.rn.ftz.f32 	%f22, %f4, %f4, %f21;
	rsqrt.approx.ftz.f32 	%f23, %f22;
	mul.ftz.f32 	%f24, %f2, %f23;
	mul.ftz.f32 	%f25, %f3, %f23;
	mul.ftz.f32 	%f26, %f4, %f23;
	ld.global.f32 	%f27, [ray+12];
	ld.global.f32 	%f28, [t_hit];
	ld.global.f32 	%f29, [ray+16];
	ld.global.f32 	%f30, [ray+20];
	ld.global.f32 	%f31, [ray];
	fma.rn.ftz.f32 	%f10, %f28, %f27, %f31;
	ld.global.f32 	%f32, [ray+4];
	fma.rn.ftz.f32 	%f11, %f28, %f29, %f32;
	ld.global.f32 	%f33, [ray+8];
	fma.rn.ftz.f32 	%f12, %f28, %f30, %f33;
	add.ftz.f32 	%f34, %f24, %f24;
	add.ftz.f32 	%f35, %f25, %f25;
	add.ftz.f32 	%f36, %f26, %f26;
	mul.ftz.f32 	%f37, %f25, %f29;
	fma.rn.ftz.f32 	%f38, %f24, %f27, %f37;
	fma.rn.ftz.f32 	%f39, %f26, %f30, %f38;
	mul.ftz.f32 	%f40, %f34, %f39;
	mul.ftz.f32 	%f41, %f35, %f39;
	mul.ftz.f32 	%f42, %f36, %f39;
	sub.ftz.f32 	%f13, %f27, %f40;
	sub.ftz.f32 	%f14, %f29, %f41;
	sub.ftz.f32 	%f15, %f30, %f42;
	ld.global.u32 	%r4, [Phong];
	mov.f32 	%f43, 0f3F800000;
	st.local.v4.f32 	[%rd4], {%f43, %f43, %f43, %f43};
	ld.global.v2.u32 	{%r6, %r7}, [prdr+16];
	add.s32 	%r10, %r6, 1;
	st.local.v2.u32 	[%rd4+16], {%r10, %r7};
	ld.global.u32 	%r3, [top_object];
	mov.f32 	%f16, 0f360637BD;
	mov.f32 	%f17, 0f6C4ECB8F;
	mov.u32 	%r5, 32;
	// inline asm
	call _rt_trace_64, (%r3, %f10, %f11, %f12, %f13, %f14, %f15, %r4, %f16, %f17, %rd3, %r5);
	// inline asm
	ld.local.v4.f32 	{%f44, %f45, %f46, %f47}, [%rd4];
	st.global.v4.f32 	[prdr], {%f44, %f45, %f46, %f47};
	bra.uni 	BB4_3;

BB4_1:
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};

BB4_3:
	ret;
}

	// .globl	_Z15tracePathGlossyv
.visible .entry _Z15tracePathGlossyv(

)
{
	.local .align 16 .b8 	__local_depot5[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<4>;
	.reg .f32 	%f<118>;
	.reg .b32 	%r<16>;
	.reg .b64 	%rd<8>;


	mov.u64 	%rd7, __local_depot5;
	cvta.local.u64 	%SP, %rd7;
	mov.u64 	%rd1, prdr;
	add.s64 	%rd2, %rd1, 16;
	ldu.global.u32 	%r1, [%rd2];
	setp.lt.s32	%p1, %r1, 4;
	@%p1 bra 	BB5_2;
	bra.uni 	BB5_1;

BB5_2:
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	mov.u64 	%rd5, shading_normal;
	ldu.global.v2.f32 	{%f18, %f19}, [shading_normal];
	add.s64 	%rd6, %rd5, 8;
	ldu.global.f32 	%f8, [%rd6];
	mov.u32 	%r2, 7937;
	mov.f32 	%f9, 0f00000000;
	// inline asm
	call (%f2, %f3, %f4, %f5), _rt_transform_tuple, (%r2, %f18, %f19, %f8, %f9);
	// inline asm
	mul.ftz.f32 	%f20, %f3, %f3;
	fma.rn.ftz.f32 	%f21, %f2, %f2, %f20;
	fma.rn.ftz.f32 	%f22, %f4, %f4, %f21;
	rsqrt.approx.ftz.f32 	%f23, %f22;
	mul.ftz.f32 	%f24, %f2, %f23;
	mul.ftz.f32 	%f25, %f3, %f23;
	mul.ftz.f32 	%f26, %f4, %f23;
	ld.global.f32 	%f27, [ray+12];
	ld.global.f32 	%f28, [t_hit];
	ld.global.f32 	%f29, [ray+16];
	ld.global.f32 	%f30, [ray+20];
	ld.global.f32 	%f31, [ray];
	fma.rn.ftz.f32 	%f10, %f28, %f27, %f31;
	ld.global.f32 	%f32, [ray+4];
	fma.rn.ftz.f32 	%f11, %f28, %f29, %f32;
	ld.global.f32 	%f33, [ray+8];
	fma.rn.ftz.f32 	%f12, %f28, %f30, %f33;
	add.ftz.f32 	%f34, %f24, %f24;
	add.ftz.f32 	%f35, %f25, %f25;
	add.ftz.f32 	%f36, %f26, %f26;
	mul.ftz.f32 	%f37, %f25, %f29;
	fma.rn.ftz.f32 	%f38, %f24, %f27, %f37;
	fma.rn.ftz.f32 	%f39, %f26, %f30, %f38;
	mul.ftz.f32 	%f40, %f34, %f39;
	mul.ftz.f32 	%f41, %f35, %f39;
	mul.ftz.f32 	%f42, %f36, %f39;
	sub.ftz.f32 	%f43, %f27, %f40;
	sub.ftz.f32 	%f44, %f29, %f41;
	sub.ftz.f32 	%f45, %f30, %f42;
	ld.global.v2.u32 	{%r6, %r7}, [prdr+16];
	mad.lo.s32 	%r10, %r7, 1664525, 1013904223;
	and.b32  	%r11, %r10, 16777215;
	cvt.rn.f32.u32	%f46, %r11;
	mov.f32 	%f47, 0f4B800000;
	div.approx.ftz.f32 	%f48, %f46, %f47;
	mad.lo.s32 	%r12, %r10, 1664525, 1013904223;
	st.global.u32 	[prdr+20], %r12;
	and.b32  	%r13, %r12, 16777215;
	cvt.rn.f32.u32	%f49, %r13;
	div.approx.ftz.f32 	%f50, %f49, %f47;
	mul.ftz.f32 	%f51, %f44, 0f00000000;
	sub.ftz.f32 	%f52, %f51, %f45;
	mul.ftz.f32 	%f53, %f45, 0f00000000;
	mul.ftz.f32 	%f54, %f43, 0f00000000;
	sub.ftz.f32 	%f55, %f53, %f54;
	sub.ftz.f32 	%f56, %f43, %f51;
	mul.ftz.f32 	%f57, %f55, %f55;
	fma.rn.ftz.f32 	%f58, %f52, %f52, %f57;
	fma.rn.ftz.f32 	%f59, %f56, %f56, %f58;
	setp.lt.ftz.f32	%p2, %f59, 0f3A83126F;
	sub.ftz.f32 	%f60, %f51, %f53;
	sub.ftz.f32 	%f61, %f45, %f54;
	sub.ftz.f32 	%f62, %f54, %f44;
	selp.f32	%f63, %f60, %f52, %p2;
	selp.f32	%f64, %f61, %f55, %p2;
	selp.f32	%f65, %f62, %f56, %p2;
	mul.ftz.f32 	%f66, %f64, %f64;
	fma.rn.ftz.f32 	%f67, %f63, %f63, %f66;
	fma.rn.ftz.f32 	%f68, %f65, %f65, %f67;
	rsqrt.approx.ftz.f32 	%f69, %f68;
	mul.ftz.f32 	%f70, %f69, %f63;
	mul.ftz.f32 	%f71, %f69, %f64;
	mul.ftz.f32 	%f72, %f69, %f65;
	mul.ftz.f32 	%f73, %f45, %f71;
	mul.ftz.f32 	%f74, %f44, %f72;
	sub.ftz.f32 	%f75, %f73, %f74;
	mul.ftz.f32 	%f76, %f43, %f72;
	mul.ftz.f32 	%f77, %f45, %f70;
	sub.ftz.f32 	%f78, %f76, %f77;
	mul.ftz.f32 	%f79, %f44, %f70;
	mul.ftz.f32 	%f80, %f43, %f71;
	sub.ftz.f32 	%f81, %f79, %f80;
	lg2.approx.ftz.f32 	%f82, %f50;
	mul.ftz.f32 	%f83, %f82, 0f3F317218;
	mov.f32 	%f84, 0f42CA0000;
	div.approx.ftz.f32 	%f85, %f83, %f84;
	mul.ftz.f32 	%f86, %f85, 0f3FB8AA3B;
	ex2.approx.ftz.f32 	%f87, %f86;
	add.ftz.f32 	%f88, %f48, %f48;
	mul.ftz.f32 	%f89, %f88, 0f40490FDB;
	mul.ftz.f32 	%f90, %f87, %f87;
	mov.f32 	%f91, 0f3F800000;
	sub.ftz.f32 	%f92, %f91, %f90;
	sqrt.approx.ftz.f32 	%f93, %f92;
	cos.approx.ftz.f32 	%f94, %f89;
	mul.ftz.f32 	%f95, %f93, %f94;
	sin.approx.ftz.f32 	%f96, %f89;
	mul.ftz.f32 	%f97, %f93, %f96;
	mul.ftz.f32 	%f98, %f95, %f75;
	mul.ftz.f32 	%f99, %f95, %f78;
	mul.ftz.f32 	%f100, %f95, %f81;
	fma.rn.ftz.f32 	%f101, %f97, %f70, %f98;
	fma.rn.ftz.f32 	%f102, %f97, %f71, %f99;
	fma.rn.ftz.f32 	%f103, %f97, %f72, %f100;
	fma.rn.ftz.f32 	%f104, %f43, %f87, %f101;
	fma.rn.ftz.f32 	%f105, %f44, %f87, %f102;
	fma.rn.ftz.f32 	%f106, %f45, %f87, %f103;
	mul.ftz.f32 	%f107, %f25, %f105;
	fma.rn.ftz.f32 	%f108, %f24, %f104, %f107;
	fma.rn.ftz.f32 	%f109, %f26, %f106, %f108;
	setp.gtu.ftz.f32	%p3, %f109, 0f00000000;
	selp.f32	%f15, %f106, %f45, %p3;
	selp.f32	%f14, %f105, %f44, %p3;
	selp.f32	%f13, %f104, %f43, %p3;
	ld.global.u32 	%r4, [Phong];
	st.local.v4.f32 	[%rd4], {%f91, %f91, %f91, %f91};
	add.s32 	%r14, %r6, 1;
	st.local.u32 	[%rd4+16], %r14;
	ld.global.u32 	%r15, [prdr+20];
	st.local.u32 	[%rd4+20], %r15;
	ld.global.u32 	%r3, [top_object];
	mov.f32 	%f16, 0f360637BD;
	mov.f32 	%f17, 0f6C4ECB8F;
	mov.u32 	%r5, 32;
	// inline asm
	call _rt_trace_64, (%r3, %f10, %f11, %f12, %f13, %f14, %f15, %r4, %f16, %f17, %rd3, %r5);
	// inline asm
	ld.local.v4.f32 	{%f110, %f111, %f112, %f113}, [%rd4];
	st.global.v4.f32 	[prdr], {%f110, %f111, %f112, %f113};
	bra.uni 	BB5_3;

BB5_1:
	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};

BB5_3:
	ret;
}

	// .globl	_Z9tracePathv
.visible .entry _Z9tracePathv(

)
{
	.local .align 16 .b8 	__local_depot6[64];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<8>;
	.reg .f32 	%f<266>;
	.reg .b32 	%r<23>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<14>;


	mov.u64 	%rd13, __local_depot6;
	cvta.local.u64 	%SP, %rd13;
	add.u64 	%rd4, %SP, 32;
	cvta.to.local.u64 	%rd2, %rd4;
	add.u64 	%rd5, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd5;
	mov.f32 	%f256, 0f00000000;
	st.local.v4.f32 	[%rd1], {%f256, %f256, %f256, %f256};
	mov.u64 	%rd6, shading_normal;
	ldu.global.v2.f32 	{%f82, %f83}, [shading_normal];
	add.s64 	%rd7, %rd6, 8;
	ldu.global.f32 	%f76, [%rd7];
	mov.u32 	%r3, 7937;
	// inline asm
	call (%f70, %f71, %f72, %f73), _rt_transform_tuple, (%r3, %f82, %f83, %f76, %f256);
	// inline asm
	mul.ftz.f32 	%f84, %f71, %f71;
	fma.rn.ftz.f32 	%f85, %f70, %f70, %f84;
	fma.rn.ftz.f32 	%f86, %f72, %f72, %f85;
	rsqrt.approx.ftz.f32 	%f87, %f86;
	mul.ftz.f32 	%f1, %f70, %f87;
	mul.ftz.f32 	%f2, %f71, %f87;
	mul.ftz.f32 	%f3, %f72, %f87;
	ld.global.f32 	%f88, [ray+12];
	ld.global.f32 	%f89, [t_hit];
	ld.global.f32 	%f90, [ray+16];
	ld.global.f32 	%f91, [ray+20];
	ld.global.f32 	%f92, [ray];
	fma.rn.ftz.f32 	%f4, %f89, %f88, %f92;
	ld.global.f32 	%f93, [ray+4];
	fma.rn.ftz.f32 	%f5, %f89, %f90, %f93;
	ld.global.f32 	%f94, [ray+8];
	fma.rn.ftz.f32 	%f6, %f89, %f91, %f94;
	ld.global.v4.f32 	{%f95, %f96, %f97, %f98}, [lightPos];
	st.local.v4.f32 	[%rd2], {%f256, %f256, %f256, %f256};
	sub.ftz.f32 	%f99, %f4, %f95;
	sub.ftz.f32 	%f100, %f5, %f96;
	sub.ftz.f32 	%f101, %f6, %f97;
	neg.ftz.f32 	%f102, %f100;
	fma.rn.ftz.f32 	%f103, %f99, 0f00000000, %f102;
	fma.rn.ftz.f32 	%f104, %f101, 0f00000000, %f103;
	setp.lt.ftz.f32	%p1, %f104, 0f00000000;
	mov.f32 	%f255, %f256;
	mov.f32 	%f254, %f256;
	mov.f32 	%f253, %f256;
	@%p1 bra 	BB6_4;

	ld.global.u32 	%r4, [prdr+20];
	mad.lo.s32 	%r5, %r4, 1664525, 1013904223;
	and.b32  	%r6, %r5, 16777215;
	cvt.rn.f32.u32	%f108, %r6;
	mov.f32 	%f109, 0f4B800000;
	div.approx.ftz.f32 	%f110, %f108, %f109;
	mad.lo.s32 	%r7, %r5, 1664525, 1013904223;
	st.global.u32 	[prdr+20], %r7;
	and.b32  	%r8, %r7, 16777215;
	cvt.rn.f32.u32	%f111, %r8;
	div.approx.ftz.f32 	%f112, %f111, %f109;
	fma.rn.ftz.f32 	%f113, %f110, 0f3ECCCCCD, %f95;
	fma.rn.ftz.f32 	%f114, %f110, 0f00000000, %f96;
	fma.rn.ftz.f32 	%f115, %f110, 0f00000000, %f97;
	fma.rn.ftz.f32 	%f116, %f112, 0f00000000, %f113;
	fma.rn.ftz.f32 	%f117, %f112, 0f00000000, %f114;
	fma.rn.ftz.f32 	%f118, %f112, 0f3EE66666, %f115;
	sub.ftz.f32 	%f119, %f116, %f4;
	sub.ftz.f32 	%f120, %f117, %f5;
	sub.ftz.f32 	%f121, %f118, %f6;
	mul.ftz.f32 	%f122, %f120, %f120;
	fma.rn.ftz.f32 	%f123, %f119, %f119, %f122;
	fma.rn.ftz.f32 	%f124, %f121, %f121, %f123;
	sqrt.approx.ftz.f32 	%f10, %f124;
	rsqrt.approx.ftz.f32 	%f125, %f124;
	mul.ftz.f32 	%f11, %f125, %f119;
	mul.ftz.f32 	%f12, %f125, %f120;
	mul.ftz.f32 	%f13, %f125, %f121;
	mul.ftz.f32 	%f126, %f2, %f12;
	fma.rn.ftz.f32 	%f127, %f1, %f11, %f126;
	fma.rn.ftz.f32 	%f14, %f3, %f13, %f127;
	mov.f32 	%f252, 0f00000000;
	mov.f32 	%f251, %f252;
	mov.f32 	%f250, %f252;
	setp.leu.ftz.f32	%p2, %f14, 0f00000000;
	@%p2 bra 	BB6_3;

	fma.rn.ftz.f32 	%f136, %f11, 0f80000000, %f12;
	fma.rn.ftz.f32 	%f137, %f13, 0f80000000, %f136;
	mov.f32 	%f138, 0f00000000;
	max.ftz.f32 	%f139, %f138, %f137;
	mov.f32 	%f140, 0f3F800000;
	st.local.v4.f32 	[%rd2], {%f140, %f140, %f140, %f140};
	ld.global.u32 	%r10, [Shadow];
	cvt.ftz.f64.f32	%fd1, %f10;
	add.f64 	%fd2, %fd1, 0d3F847AE147AE147B;
	cvt.rn.ftz.f32.f64	%f135, %fd2;
	ld.global.u32 	%r9, [top_object];
	mov.f32 	%f134, 0f3DCCCCCD;
	mov.u32 	%r11, 32;
	// inline asm
	call _rt_trace_64, (%r9, %f4, %f5, %f6, %f11, %f12, %f13, %r10, %f134, %f135, %rd4, %r11);
	// inline asm
	ld.local.v4.f32 	{%f141, %f142, %f143, %f144}, [%rd2];
	mul.ftz.f32 	%f146, %f14, %f141;
	mul.ftz.f32 	%f148, %f14, %f142;
	mul.ftz.f32 	%f150, %f14, %f143;
	fma.rn.ftz.f32 	%f250, %f139, %f146, 0f00000000;
	fma.rn.ftz.f32 	%f251, %f139, %f148, 0f00000000;
	fma.rn.ftz.f32 	%f252, %f139, %f150, 0f00000000;

BB6_3:
	mov.f32 	%f256, 0f3F800000;
	mov.f32 	%f255, %f252;
	mov.f32 	%f254, %f251;
	mov.f32 	%f253, %f250;

BB6_4:
	mov.f32 	%f258, %f253;
	mov.f32 	%f259, %f254;
	mov.f32 	%f260, %f255;
	mov.f32 	%f261, %f256;
	ld.global.v4.f32 	{%f151, %f152, %f153, %f154}, [diffuse];
	mov.f32 	%f265, %f154;
	mov.f32 	%f262, %f151;
	mov.f32 	%f264, %f153;
	mov.f32 	%f263, %f152;
	max.ftz.f32 	%f155, %f152, %f153;
	max.ftz.f32 	%f37, %f151, %f155;
	ld.global.u64 	%rd3, [prdr+16];
	cvt.u32.u64	%r1, %rd3;
	setp.gt.s32	%p3, %r1, 1;
	@%p3 bra 	BB6_9;

	shr.u64 	%rd9, %rd3, 32;
	cvt.u32.u64	%r12, %rd9;
	mad.lo.s32 	%r2, %r12, 1664525, 1013904223;
	st.global.u32 	[prdr+20], %r2;
	and.b32  	%r13, %r2, 16777215;
	cvt.rn.f32.u32	%f156, %r13;
	mov.f32 	%f157, 0f4B800000;
	div.approx.ftz.f32 	%f158, %f156, %f157;
	setp.gt.ftz.f32	%p4, %f158, %f37;
	@%p4 bra 	BB6_9;
	bra.uni 	BB6_6;

BB6_9:
	mov.f32 	%f223, 0f3F800000;
	sub.ftz.f32 	%f224, %f223, %f37;
	rcp.approx.ftz.f32 	%f225, %f224;
	mul.ftz.f32 	%f262, %f151, %f225;
	mul.ftz.f32 	%f263, %f152, %f225;
	mul.ftz.f32 	%f264, %f153, %f225;
	mul.ftz.f32 	%f265, %f154, %f225;
	bra.uni 	BB6_10;

BB6_6:
	add.s32 	%r14, %r1, 1;
	mov.f32 	%f160, 0f3F800000;
	st.local.v4.f32 	[%rd1], {%f160, %f160, %f160, %f160};
	st.local.v2.u32 	[%rd1+16], {%r14, %r2};
	mad.lo.s32 	%r15, %r2, 1664525, 1013904223;
	and.b32  	%r16, %r15, 16777215;
	cvt.rn.f32.u32	%f161, %r16;
	div.approx.ftz.f32 	%f163, %f161, %f157;
	mad.lo.s32 	%r17, %r15, 1664525, 1013904223;
	st.global.u32 	[prdr+20], %r17;
	and.b32  	%r18, %r17, 16777215;
	cvt.rn.f32.u32	%f164, %r18;
	div.approx.ftz.f32 	%f165, %f164, %f157;
	mul.ftz.f32 	%f166, %f2, 0f00000000;
	sub.ftz.f32 	%f167, %f166, %f3;
	mul.ftz.f32 	%f168, %f1, 0f00000000;
	mul.ftz.f32 	%f169, %f3, 0f00000000;
	sub.ftz.f32 	%f170, %f169, %f168;
	sub.ftz.f32 	%f171, %f1, %f166;
	mul.ftz.f32 	%f172, %f170, %f170;
	fma.rn.ftz.f32 	%f173, %f167, %f167, %f172;
	fma.rn.ftz.f32 	%f174, %f171, %f171, %f173;
	setp.lt.ftz.f32	%p5, %f174, 0f3A83126F;
	sub.ftz.f32 	%f175, %f166, %f169;
	sub.ftz.f32 	%f176, %f3, %f168;
	sub.ftz.f32 	%f177, %f168, %f2;
	selp.f32	%f178, %f175, %f167, %p5;
	selp.f32	%f179, %f176, %f170, %p5;
	selp.f32	%f180, %f177, %f171, %p5;
	mul.ftz.f32 	%f181, %f179, %f179;
	fma.rn.ftz.f32 	%f182, %f178, %f178, %f181;
	fma.rn.ftz.f32 	%f183, %f180, %f180, %f182;
	rsqrt.approx.ftz.f32 	%f184, %f183;
	mul.ftz.f32 	%f38, %f178, %f184;
	mul.ftz.f32 	%f39, %f179, %f184;
	mul.ftz.f32 	%f40, %f180, %f184;
	mul.ftz.f32 	%f185, %f163, 0f40C90FDB;
	sqrt.approx.ftz.f32 	%f186, %f165;
	cos.approx.ftz.f32 	%f187, %f185;
	mul.ftz.f32 	%f41, %f186, %f187;
	sin.approx.ftz.f32 	%f188, %f185;
	mul.ftz.f32 	%f42, %f186, %f188;
	mul.ftz.f32 	%f189, %f41, %f41;
	sub.ftz.f32 	%f190, %f160, %f189;
	mul.ftz.f32 	%f191, %f42, %f42;
	sub.ftz.f32 	%f43, %f190, %f191;
	mov.f32 	%f257, 0f00000000;
	setp.leu.ftz.f32	%p6, %f43, 0f00000000;
	@%p6 bra 	BB6_8;

	sqrt.approx.ftz.f32 	%f257, %f43;

BB6_8:
	mul.ftz.f32 	%f200, %f3, %f39;
	mul.ftz.f32 	%f201, %f2, %f40;
	sub.ftz.f32 	%f202, %f200, %f201;
	mul.ftz.f32 	%f203, %f1, %f40;
	mul.ftz.f32 	%f204, %f3, %f38;
	sub.ftz.f32 	%f205, %f203, %f204;
	mul.ftz.f32 	%f206, %f2, %f38;
	mul.ftz.f32 	%f207, %f1, %f39;
	sub.ftz.f32 	%f208, %f206, %f207;
	mul.ftz.f32 	%f209, %f38, %f42;
	fma.rn.ftz.f32 	%f210, %f202, %f41, %f209;
	mul.ftz.f32 	%f211, %f39, %f42;
	fma.rn.ftz.f32 	%f212, %f205, %f41, %f211;
	mul.ftz.f32 	%f213, %f40, %f42;
	fma.rn.ftz.f32 	%f214, %f208, %f41, %f213;
	fma.rn.ftz.f32 	%f195, %f1, %f257, %f210;
	fma.rn.ftz.f32 	%f196, %f2, %f257, %f212;
	fma.rn.ftz.f32 	%f197, %f3, %f257, %f214;
	ld.global.u32 	%r20, [Phong];
	ld.global.u32 	%r19, [top_object];
	mov.f32 	%f198, 0f3E4CCCCD;
	mov.f32 	%f199, 0f4A989680;
	mov.u32 	%r21, 32;
	// inline asm
	call _rt_trace_64, (%r19, %f4, %f5, %f6, %f195, %f196, %f197, %r20, %f198, %f199, %rd5, %r21);
	// inline asm
	ld.local.v4.f32 	{%f215, %f216, %f217, %f218}, [%rd1];
	add.ftz.f32 	%f258, %f253, %f215;
	add.ftz.f32 	%f259, %f254, %f216;
	add.ftz.f32 	%f260, %f255, %f217;
	add.ftz.f32 	%f261, %f256, %f218;

BB6_10:
	ld.global.u32 	%r22, [texCount];
	setp.lt.s32	%p7, %r22, 1;
	@%p7 bra 	BB6_12;

	ld.global.v2.f32 	{%f226, %f227}, [texCoord];
	tex.2d.v4.f32.f32	{%f230, %f231, %f232, %f233}, [tex0, {%f226, %f227}];
	mul.ftz.f32 	%f262, %f262, %f230;
	mul.ftz.f32 	%f263, %f263, %f231;
	mul.ftz.f32 	%f264, %f264, %f232;
	mul.ftz.f32 	%f265, %f265, %f233;

BB6_12:
	mul.ftz.f32 	%f234, %f258, %f262;
	ld.global.v4.f32 	{%f235, %f236, %f237, %f238}, [prdr];
	mul.ftz.f32 	%f240, %f261, %f265;
	mul.ftz.f32 	%f241, %f240, %f238;
	mul.ftz.f32 	%f242, %f260, %f264;
	mul.ftz.f32 	%f244, %f242, %f237;
	mul.ftz.f32 	%f245, %f259, %f263;
	mul.ftz.f32 	%f247, %f245, %f236;
	mul.ftz.f32 	%f249, %f234, %f235;
	st.global.v4.f32 	[prdr], {%f249, %f247, %f244, %f241};
	ret;
}

	// .globl	_Z10shadeLightv
.visible .entry _Z10shadeLightv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f3F800000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z10shadeGlassv
.visible .entry _Z10shadeGlassv(

)
{
	.local .align 16 .b8 	__local_depot8[32];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .f32 	%f<161>;
	.reg .b32 	%r<21>;
	.reg .f64 	%fd<42>;
	.reg .b64 	%rd<6>;


	mov.u64 	%rd5, __local_depot8;
	cvta.local.u64 	%SP, %rd5;
	mov.u64 	%rd1, shading_normal;
	ldu.global.v2.f32 	{%f56, %f57}, [shading_normal];
	add.s64 	%rd2, %rd1, 8;
	ldu.global.f32 	%f54, [%rd2];
	mov.u32 	%r4, 7937;
	mov.f32 	%f159, 0f00000000;
	// inline asm
	call (%f48, %f49, %f50, %f51), _rt_transform_tuple, (%r4, %f56, %f57, %f54, %f159);
	// inline asm
	mul.ftz.f32 	%f58, %f49, %f49;
	fma.rn.ftz.f32 	%f59, %f48, %f48, %f58;
	fma.rn.ftz.f32 	%f60, %f50, %f50, %f59;
	rsqrt.approx.ftz.f32 	%f61, %f60;
	mul.ftz.f32 	%f147, %f48, %f61;
	mul.ftz.f32 	%f150, %f49, %f61;
	mul.ftz.f32 	%f153, %f50, %f61;
	ld.global.f32 	%f8, [ray+12];
	ld.global.f32 	%f4, [t_hit];
	ld.global.f32 	%f9, [ray+16];
	ld.global.f32 	%f10, [ray+20];
	ld.global.f32 	%f62, [ray];
	fma.rn.ftz.f32 	%f5, %f4, %f8, %f62;
	ld.global.f32 	%f63, [ray+4];
	fma.rn.ftz.f32 	%f6, %f4, %f9, %f63;
	ld.global.f32 	%f64, [ray+8];
	fma.rn.ftz.f32 	%f7, %f4, %f10, %f64;
	mul.ftz.f32 	%f65, %f150, %f9;
	fma.rn.ftz.f32 	%f66, %f147, %f8, %f65;
	fma.rn.ftz.f32 	%f155, %f153, %f10, %f66;
	setp.lt.ftz.f32	%p1, %f155, 0f00000000;
	@%p1 bra 	BB8_9;
	bra.uni 	BB8_1;

BB8_9:
	mov.f32 	%f156, 0f3F2AAAAB;
	setp.leu.ftz.f32	%p7, %f155, 0f00000000;
	@%p7 bra 	BB8_11;

	neg.ftz.f32 	%f147, %f147;
	neg.ftz.f32 	%f150, %f150;
	neg.ftz.f32 	%f153, %f153;
	neg.ftz.f32 	%f155, %f155;
	mov.f32 	%f156, 0f3FC00000;

BB8_11:
	mul.ftz.f32 	%f103, %f155, %f155;
	mov.f32 	%f160, 0f3F800000;
	sub.ftz.f32 	%f104, %f160, %f103;
	mul.ftz.f32 	%f105, %f156, %f156;
	mul.ftz.f32 	%f106, %f105, %f104;
	sub.ftz.f32 	%f40, %f160, %f106;
	setp.lt.ftz.f32	%p8, %f40, 0f00000000;
	mov.f32 	%f159, 0f00000000;
	mov.f32 	%f158, %f159;
	mov.f32 	%f157, %f159;
	@%p8 bra 	BB8_13;

	mul.ftz.f32 	%f108, %f8, %f156;
	sqrt.approx.ftz.f32 	%f109, %f40;
	fma.rn.ftz.f32 	%f110, %f155, %f156, %f109;
	mul.ftz.f32 	%f111, %f147, %f110;
	mul.ftz.f32 	%f112, %f150, %f110;
	mul.ftz.f32 	%f113, %f153, %f110;
	sub.ftz.f32 	%f114, %f108, %f111;
	mul.ftz.f32 	%f115, %f9, %f156;
	sub.ftz.f32 	%f116, %f115, %f112;
	mul.ftz.f32 	%f117, %f10, %f156;
	sub.ftz.f32 	%f118, %f117, %f113;
	mul.ftz.f32 	%f119, %f116, %f116;
	fma.rn.ftz.f32 	%f120, %f114, %f114, %f119;
	fma.rn.ftz.f32 	%f121, %f118, %f118, %f120;
	rsqrt.approx.ftz.f32 	%f122, %f121;
	mul.ftz.f32 	%f159, %f122, %f114;
	mul.ftz.f32 	%f158, %f122, %f116;
	mul.ftz.f32 	%f157, %f122, %f118;
	bra.uni 	BB8_13;

BB8_1:
	neg.ftz.f32 	%f148, %f147;
	mul.ftz.f32 	%f68, %f8, %f148;
	neg.ftz.f32 	%f151, %f150;
	mul.ftz.f32 	%f69, %f9, %f150;
	sub.ftz.f32 	%f70, %f68, %f69;
	neg.ftz.f32 	%f154, %f153;
	mul.ftz.f32 	%f71, %f10, %f153;
	sub.ftz.f32 	%f144, %f70, %f71;
	mov.f32 	%f145, 0f3FC1F07C;
	setp.leu.ftz.f32	%p2, %f144, 0f00000000;
	@%p2 bra 	BB8_3;

	neg.ftz.f32 	%f144, %f144;
	mov.f32 	%f145, 0f3F28F5C3;
	mov.f32 	%f148, %f147;
	mov.f32 	%f151, %f150;
	mov.f32 	%f154, %f153;

BB8_3:
	mul.ftz.f32 	%f76, %f144, %f144;
	mov.f32 	%f77, 0f3F800000;
	sub.ftz.f32 	%f78, %f77, %f76;
	mul.ftz.f32 	%f79, %f145, %f145;
	mul.ftz.f32 	%f80, %f79, %f78;
	sub.ftz.f32 	%f22, %f77, %f80;
	setp.lt.ftz.f32	%p3, %f22, 0f00000000;
	mov.f32 	%f158, %f159;
	mov.f32 	%f157, %f159;
	@%p3 bra 	BB8_5;

	mul.ftz.f32 	%f81, %f8, %f145;
	sqrt.approx.ftz.f32 	%f82, %f22;
	fma.rn.ftz.f32 	%f83, %f144, %f145, %f82;
	mul.ftz.f32 	%f84, %f148, %f83;
	mul.ftz.f32 	%f85, %f151, %f83;
	mul.ftz.f32 	%f86, %f154, %f83;
	sub.ftz.f32 	%f87, %f81, %f84;
	mul.ftz.f32 	%f88, %f9, %f145;
	sub.ftz.f32 	%f89, %f88, %f85;
	mul.ftz.f32 	%f90, %f10, %f145;
	sub.ftz.f32 	%f91, %f90, %f86;
	mul.ftz.f32 	%f92, %f89, %f89;
	fma.rn.ftz.f32 	%f93, %f87, %f87, %f92;
	fma.rn.ftz.f32 	%f94, %f91, %f91, %f93;
	rsqrt.approx.ftz.f32 	%f95, %f94;
	mul.ftz.f32 	%f159, %f95, %f87;
	mul.ftz.f32 	%f158, %f95, %f89;
	mul.ftz.f32 	%f157, %f95, %f91;

BB8_5:
	cvt.ftz.f64.f32	%fd6, %f4;
	mul.f64 	%fd1, %fd6, 0dBFC6513637DDE829;
	mov.f64 	%fd7, 0d4338000000000000;
	mov.f64 	%fd8, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd9, %fd1, %fd8, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1, %temp}, %fd9;
	}
	mov.f64 	%fd10, 0dC338000000000000;
	add.rn.f64 	%fd11, %fd9, %fd10;
	mov.f64 	%fd12, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd13, %fd11, %fd12, %fd1;
	mov.f64 	%fd14, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd15, %fd11, %fd14, %fd13;
	mov.f64 	%fd16, 0d3E928AF3FCA213EA;
	mov.f64 	%fd17, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd18, %fd17, %fd15, %fd16;
	mov.f64 	%fd19, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd20, %fd18, %fd15, %fd19;
	mov.f64 	%fd21, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd22, %fd20, %fd15, %fd21;
	mov.f64 	%fd23, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd24, %fd22, %fd15, %fd23;
	mov.f64 	%fd25, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd26, %fd24, %fd15, %fd25;
	mov.f64 	%fd27, 0d3F81111111122322;
	fma.rn.f64 	%fd28, %fd26, %fd15, %fd27;
	mov.f64 	%fd29, 0d3FA55555555502A1;
	fma.rn.f64 	%fd30, %fd28, %fd15, %fd29;
	mov.f64 	%fd31, 0d3FC5555555555511;
	fma.rn.f64 	%fd32, %fd30, %fd15, %fd31;
	mov.f64 	%fd33, 0d3FE000000000000B;
	fma.rn.f64 	%fd34, %fd32, %fd15, %fd33;
	mov.f64 	%fd35, 0d3FF0000000000000;
	fma.rn.f64 	%fd36, %fd34, %fd15, %fd35;
	fma.rn.f64 	%fd37, %fd36, %fd15, %fd35;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r2, %temp}, %fd37;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd37;
	}
	shl.b32 	%r5, %r1, 20;
	add.s32 	%r6, %r3, %r5;
	mov.b64 	%fd41, {%r2, %r6};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r7}, %fd1;
	}
	mov.b32 	 %f96, %r7;
	abs.ftz.f32 	%f29, %f96;
	setp.lt.ftz.f32	%p4, %f29, 0f4086232B;
	@%p4 bra 	BB8_8;

	setp.lt.f64	%p5, %fd1, 0d0000000000000000;
	add.f64 	%fd38, %fd1, 0d7FF0000000000000;
	selp.f64	%fd41, 0d0000000000000000, %fd38, %p5;
	setp.geu.ftz.f32	%p6, %f29, 0f40874800;
	@%p6 bra 	BB8_8;

	shr.u32 	%r8, %r1, 31;
	add.s32 	%r9, %r1, %r8;
	shr.s32 	%r10, %r9, 1;
	shl.b32 	%r11, %r10, 20;
	add.s32 	%r12, %r11, %r3;
	mov.b64 	%fd39, {%r2, %r12};
	sub.s32 	%r13, %r1, %r10;
	shl.b32 	%r14, %r13, 20;
	add.s32 	%r15, %r14, 1072693248;
	mov.u32 	%r16, 0;
	mov.b64 	%fd40, {%r16, %r15};
	mul.f64 	%fd41, %fd39, %fd40;

BB8_8:
	cvt.rn.ftz.f32.f64	%f160, %fd41;

BB8_13:
	ld.global.u32 	%r18, [Phong];
	add.u64 	%rd3, %SP, 0;
	cvta.to.local.u64 	%rd4, %rd3;
	mov.f32 	%f131, 0f3F800000;
	st.local.v4.f32 	[%rd4], {%f131, %f131, %f131, %f131};
	ld.global.u32 	%r20, [prdr+16];
	st.local.u32 	[%rd4+16], %r20;
	ld.global.u32 	%r17, [top_object];
	mov.f32 	%f129, 0f360637BD;
	mov.f32 	%f130, 0f6C4ECB8F;
	mov.u32 	%r19, 32;
	// inline asm
	call _rt_trace_64, (%r17, %f5, %f6, %f7, %f159, %f158, %f157, %r18, %f129, %f130, %rd3, %r19);
	// inline asm
	ld.local.v4.f32 	{%f132, %f133, %f134, %f135}, [%rd4];
	mul.ftz.f32 	%f140, %f160, %f135;
	mul.ftz.f32 	%f141, %f160, %f134;
	mul.ftz.f32 	%f142, %f160, %f133;
	mul.ftz.f32 	%f143, %f160, %f132;
	st.global.v4.f32 	[prdr], {%f143, %f142, %f141, %f140};
	ret;
}

	// .globl	_Z9exceptionv
.visible .entry _Z9exceptionv(

)
{
	.reg .f32 	%f<3>;
	.reg .b32 	%r<7>;
	.reg .b64 	%rd<8>;


	ld.global.v2.u32 	{%r3, %r4}, [launch_index];
	cvt.u64.u32	%rd3, %r3;
	cvt.u64.u32	%rd4, %r4;
	mov.u64 	%rd7, output0;
	cvta.global.u64 	%rd2, %rd7;
	mov.u32 	%r1, 2;
	mov.u32 	%r2, 16;
	mov.u64 	%rd6, 0;
	// inline asm
	call (%rd1), _rt_buffer_get_64, (%rd2, %r1, %r2, %rd3, %rd4, %rd6, %rd6);
	// inline asm
	mov.f32 	%f1, 0f00000000;
	mov.f32 	%f2, 0f3F800000;
	st.v4.f32 	[%rd1], {%f2, %f1, %f1, %f2};
	ret;
}

	// .globl	_Z4missv
.visible .entry _Z4missv(

)
{
	.reg .f32 	%f<2>;


	mov.f32 	%f1, 0f00000000;
	st.global.v4.f32 	[prdr], {%f1, %f1, %f1, %f1};
	ret;
}

	// .globl	_Z20geometryintersectioni
.visible .entry _Z20geometryintersectioni(
	.param .u32 _Z20geometryintersectioni_param_0
)
{
	.reg .pred 	%p<11>;
	.reg .f32 	%f<152>;
	.reg .b32 	%r<44>;
	.reg .b64 	%rd<117>;


	ld.param.u32 	%r13, [_Z20geometryintersectioni_param_0];
	mul.lo.s32 	%r14, %r13, 3;
	cvt.s64.s32	%rd6, %r14;
	mov.u64 	%rd40, index_buffer;
	cvta.global.u64 	%rd5, %rd40;
	mov.u32 	%r11, 1;
	mov.u32 	%r10, 4;
	mov.u64 	%rd39, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd12, [%rd4];
	mov.u64 	%rd41, vertex_buffer;
	cvta.global.u64 	%rd11, %rd41;
	mov.u32 	%r12, 16;
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd12, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f7, %f8, %f9, %f10}, [%rd10];
	add.s32 	%r15, %r14, 1;
	cvt.s64.s32	%rd18, %r15;
	// inline asm
	call (%rd16), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd24, [%rd16];
	// inline asm
	call (%rd22), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd24, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f14, %f15, %f16, %f17}, [%rd22];
	add.s32 	%r16, %r14, 2;
	cvt.s64.s32	%rd30, %r16;
	// inline asm
	call (%rd28), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd36, [%rd28];
	// inline asm
	call (%rd34), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd36, %rd39, %rd39, %rd39);
	// inline asm
	sub.ftz.f32 	%f21, %f14, %f7;
	sub.ftz.f32 	%f22, %f15, %f8;
	sub.ftz.f32 	%f23, %f16, %f9;
	ld.v4.f32 	{%f24, %f25, %f26, %f27}, [%rd34];
	sub.ftz.f32 	%f31, %f7, %f24;
	sub.ftz.f32 	%f32, %f8, %f25;
	sub.ftz.f32 	%f33, %f9, %f26;
	mul.ftz.f32 	%f34, %f23, %f32;
	mul.ftz.f32 	%f35, %f22, %f33;
	sub.ftz.f32 	%f1, %f34, %f35;
	mul.ftz.f32 	%f36, %f21, %f33;
	mul.ftz.f32 	%f37, %f23, %f31;
	sub.ftz.f32 	%f2, %f36, %f37;
	mul.ftz.f32 	%f38, %f22, %f31;
	mul.ftz.f32 	%f39, %f21, %f32;
	sub.ftz.f32 	%f3, %f38, %f39;
	ld.global.f32 	%f40, [ray+12];
	ld.global.f32 	%f41, [ray+16];
	mul.ftz.f32 	%f42, %f41, %f2;
	fma.rn.ftz.f32 	%f43, %f40, %f1, %f42;
	ld.global.f32 	%f44, [ray+20];
	fma.rn.ftz.f32 	%f45, %f44, %f3, %f43;
	rcp.approx.ftz.f32 	%f46, %f45;
	ld.global.f32 	%f47, [ray];
	sub.ftz.f32 	%f48, %f7, %f47;
	ld.global.f32 	%f49, [ray+4];
	sub.ftz.f32 	%f50, %f8, %f49;
	ld.global.f32 	%f51, [ray+8];
	sub.ftz.f32 	%f52, %f9, %f51;
	mul.ftz.f32 	%f53, %f46, %f48;
	mul.ftz.f32 	%f54, %f46, %f50;
	mul.ftz.f32 	%f55, %f46, %f52;
	mul.ftz.f32 	%f56, %f41, %f55;
	mul.ftz.f32 	%f57, %f54, %f44;
	sub.ftz.f32 	%f58, %f56, %f57;
	mul.ftz.f32 	%f59, %f53, %f44;
	mul.ftz.f32 	%f60, %f55, %f40;
	sub.ftz.f32 	%f61, %f59, %f60;
	mul.ftz.f32 	%f62, %f54, %f40;
	mul.ftz.f32 	%f63, %f53, %f41;
	sub.ftz.f32 	%f64, %f62, %f63;
	mul.ftz.f32 	%f65, %f32, %f61;
	fma.rn.ftz.f32 	%f66, %f31, %f58, %f65;
	fma.rn.ftz.f32 	%f4, %f33, %f64, %f66;
	mul.ftz.f32 	%f67, %f22, %f61;
	fma.rn.ftz.f32 	%f68, %f21, %f58, %f67;
	fma.rn.ftz.f32 	%f5, %f23, %f64, %f68;
	mul.ftz.f32 	%f69, %f2, %f54;
	fma.rn.ftz.f32 	%f70, %f1, %f53, %f69;
	fma.rn.ftz.f32 	%f6, %f3, %f55, %f70;
	ld.global.f32 	%f71, [ray+32];
	setp.lt.ftz.f32	%p1, %f6, %f71;
	ld.global.f32 	%f72, [ray+28];
	setp.gt.ftz.f32	%p2, %f6, %f72;
	and.pred  	%p3, %p1, %p2;
	setp.ge.ftz.f32	%p4, %f4, 0f00000000;
	and.pred  	%p5, %p3, %p4;
	setp.ge.ftz.f32	%p6, %f5, 0f00000000;
	and.pred  	%p7, %p5, %p6;
	add.ftz.f32 	%f73, %f4, %f5;
	setp.le.ftz.f32	%p8, %f73, 0f3F800000;
	and.pred  	%p9, %p7, %p8;
	@!%p9 bra 	BB11_3;
	bra.uni 	BB11_1;

BB11_1:
	// inline asm
	call (%r17), _rt_potential_intersection, (%f6);
	// inline asm
	setp.eq.s32	%p10, %r17, 0;
	@%p10 bra 	BB11_3;

	// inline asm
	call (%rd42), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd50, [%rd42];
	mov.u64 	%rd115, normal;
	cvta.global.u64 	%rd49, %rd115;
	// inline asm
	call (%rd48), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd50, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f75, %f76, %f77, %f78}, [%rd48];
	// inline asm
	call (%rd54), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd62, [%rd54];
	// inline asm
	call (%rd60), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd62, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f82, %f83, %f84, %f85}, [%rd60];
	// inline asm
	call (%rd66), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd74, [%rd66];
	// inline asm
	call (%rd72), _rt_buffer_get_64, (%rd49, %r11, %r12, %rd74, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f89, %f90, %f91, %f92}, [%rd72];
	// inline asm
	call (%rd78), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd86, [%rd78];
	mov.u64 	%rd116, texCoord0;
	cvta.global.u64 	%rd85, %rd116;
	// inline asm
	call (%rd84), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd86, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f96, %f97, %f98, %f99}, [%rd84];
	// inline asm
	call (%rd90), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd98, [%rd90];
	// inline asm
	call (%rd96), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd98, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f103, %f104, %f105, %f106}, [%rd96];
	// inline asm
	call (%rd102), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd110, [%rd102];
	// inline asm
	call (%rd108), _rt_buffer_get_64, (%rd85, %r11, %r12, %rd110, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f110, %f111, %f112, %f113}, [%rd108];
	mov.f32 	%f117, 0f3F800000;
	sub.ftz.f32 	%f118, %f117, %f4;
	sub.ftz.f32 	%f119, %f118, %f5;
	mul.ftz.f32 	%f120, %f4, %f82;
	mul.ftz.f32 	%f121, %f4, %f83;
	mul.ftz.f32 	%f122, %f4, %f84;
	fma.rn.ftz.f32 	%f123, %f119, %f75, %f120;
	fma.rn.ftz.f32 	%f124, %f119, %f76, %f121;
	fma.rn.ftz.f32 	%f125, %f119, %f77, %f122;
	fma.rn.ftz.f32 	%f126, %f5, %f89, %f123;
	fma.rn.ftz.f32 	%f127, %f5, %f90, %f124;
	fma.rn.ftz.f32 	%f128, %f5, %f91, %f125;
	mul.ftz.f32 	%f129, %f127, %f127;
	fma.rn.ftz.f32 	%f130, %f126, %f126, %f129;
	fma.rn.ftz.f32 	%f131, %f128, %f128, %f130;
	rsqrt.approx.ftz.f32 	%f132, %f131;
	mul.ftz.f32 	%f133, %f128, %f132;
	mul.ftz.f32 	%f134, %f127, %f132;
	mul.ftz.f32 	%f135, %f126, %f132;
	st.global.v2.f32 	[shading_normal], {%f135, %f134};
	st.global.f32 	[shading_normal+8], %f133;
	mul.ftz.f32 	%f136, %f4, %f103;
	mul.ftz.f32 	%f137, %f4, %f104;
	mul.ftz.f32 	%f138, %f4, %f105;
	fma.rn.ftz.f32 	%f139, %f119, %f96, %f136;
	fma.rn.ftz.f32 	%f140, %f119, %f97, %f137;
	fma.rn.ftz.f32 	%f141, %f119, %f98, %f138;
	fma.rn.ftz.f32 	%f142, %f5, %f112, %f141;
	fma.rn.ftz.f32 	%f143, %f5, %f111, %f140;
	fma.rn.ftz.f32 	%f144, %f5, %f110, %f139;
	st.global.v2.f32 	[texCoord], {%f144, %f143};
	st.global.f32 	[texCoord+8], %f142;
	mul.ftz.f32 	%f145, %f2, %f2;
	fma.rn.ftz.f32 	%f146, %f1, %f1, %f145;
	fma.rn.ftz.f32 	%f147, %f3, %f3, %f146;
	rsqrt.approx.ftz.f32 	%f148, %f147;
	mul.ftz.f32 	%f149, %f3, %f148;
	mul.ftz.f32 	%f150, %f2, %f148;
	mul.ftz.f32 	%f151, %f1, %f148;
	st.global.v2.f32 	[geometric_normal], {%f151, %f150};
	st.global.f32 	[geometric_normal+8], %f149;
	mov.u32 	%r43, 0;
	// inline asm
	call (%r42), _rt_report_intersection, (%r43);
	// inline asm

BB11_3:
	ret;
}

	// .globl	_Z11boundingboxiPf
.visible .entry _Z11boundingboxiPf(
	.param .u32 _Z11boundingboxiPf_param_0,
	.param .u64 _Z11boundingboxiPf_param_1
)
{
	.reg .pred 	%p<6>;
	.reg .f32 	%f<54>;
	.reg .b32 	%r<19>;
	.reg .b64 	%rd<42>;


	ld.param.u32 	%r13, [_Z11boundingboxiPf_param_0];
	ld.param.u64 	%rd3, [_Z11boundingboxiPf_param_1];
	mul.lo.s32 	%r14, %r13, 3;
	cvt.s64.s32	%rd6, %r14;
	mov.u64 	%rd40, index_buffer;
	cvta.global.u64 	%rd5, %rd40;
	mov.u32 	%r11, 1;
	mov.u32 	%r10, 4;
	mov.u64 	%rd39, 0;
	// inline asm
	call (%rd4), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd6, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd12, [%rd4];
	mov.u64 	%rd41, vertex_buffer;
	cvta.global.u64 	%rd11, %rd41;
	mov.u32 	%r12, 16;
	// inline asm
	call (%rd10), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd12, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f11, %f12, %f13, %f14}, [%rd10];
	add.s32 	%r15, %r14, 1;
	cvt.s64.s32	%rd18, %r15;
	// inline asm
	call (%rd16), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd18, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd24, [%rd16];
	// inline asm
	call (%rd22), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd24, %rd39, %rd39, %rd39);
	// inline asm
	ld.v4.f32 	{%f15, %f16, %f17, %f18}, [%rd22];
	add.s32 	%r16, %r14, 2;
	cvt.s64.s32	%rd30, %r16;
	// inline asm
	call (%rd28), _rt_buffer_get_64, (%rd5, %r11, %r10, %rd30, %rd39, %rd39, %rd39);
	// inline asm
	ld.u32 	%rd36, [%rd28];
	// inline asm
	call (%rd34), _rt_buffer_get_64, (%rd11, %r11, %r12, %rd36, %rd39, %rd39, %rd39);
	// inline asm
	sub.ftz.f32 	%f19, %f15, %f11;
	sub.ftz.f32 	%f20, %f16, %f12;
	sub.ftz.f32 	%f21, %f17, %f13;
	ld.v4.f32 	{%f22, %f23, %f24, %f25}, [%rd34];
	sub.ftz.f32 	%f26, %f22, %f11;
	sub.ftz.f32 	%f27, %f23, %f12;
	sub.ftz.f32 	%f28, %f24, %f13;
	mul.ftz.f32 	%f29, %f20, %f28;
	mul.ftz.f32 	%f30, %f21, %f27;
	sub.ftz.f32 	%f31, %f29, %f30;
	mul.ftz.f32 	%f32, %f21, %f26;
	mul.ftz.f32 	%f33, %f19, %f28;
	sub.ftz.f32 	%f34, %f32, %f33;
	mul.ftz.f32 	%f35, %f19, %f27;
	mul.ftz.f32 	%f36, %f20, %f26;
	sub.ftz.f32 	%f37, %f35, %f36;
	mul.ftz.f32 	%f38, %f34, %f34;
	fma.rn.ftz.f32 	%f39, %f31, %f31, %f38;
	fma.rn.ftz.f32 	%f40, %f37, %f37, %f39;
	sqrt.approx.ftz.f32 	%f10, %f40;
	mov.pred 	%p5, 0;
	setp.leu.ftz.f32	%p4, %f10, 0f00000000;
	@%p4 bra 	BB12_2;

	abs.ftz.f32 	%f41, %f10;
	setp.neu.ftz.f32	%p5, %f41, 0f7F800000;

BB12_2:
	cvta.to.global.u64 	%rd2, %rd3;
	@%p5 bra 	BB12_4;
	bra.uni 	BB12_3;

BB12_4:
	min.ftz.f32 	%f42, %f11, %f15;
	min.ftz.f32 	%f43, %f42, %f22;
	min.ftz.f32 	%f44, %f12, %f16;
	min.ftz.f32 	%f45, %f44, %f23;
	min.ftz.f32 	%f46, %f13, %f17;
	min.ftz.f32 	%f47, %f46, %f24;
	st.global.f32 	[%rd2], %f43;
	st.global.f32 	[%rd2+4], %f45;
	st.global.f32 	[%rd2+8], %f47;
	max.ftz.f32 	%f48, %f11, %f15;
	max.ftz.f32 	%f49, %f48, %f22;
	max.ftz.f32 	%f50, %f12, %f16;
	max.ftz.f32 	%f51, %f50, %f23;
	max.ftz.f32 	%f52, %f13, %f17;
	max.ftz.f32 	%f53, %f52, %f24;
	st.global.f32 	[%rd2+12], %f49;
	st.global.f32 	[%rd2+16], %f51;
	st.global.f32 	[%rd2+20], %f53;
	bra.uni 	BB12_5;

BB12_3:
	mov.u32 	%r17, 2096152002;
	st.global.u32 	[%rd2+8], %r17;
	st.global.u32 	[%rd2+4], %r17;
	st.global.u32 	[%rd2], %r17;
	mov.u32 	%r18, -51331646;
	st.global.u32 	[%rd2+20], %r18;
	st.global.u32 	[%rd2+16], %r18;
	st.global.u32 	[%rd2+12], %r18;

BB12_5:
	ret;
}

.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0
)
{
	.reg .pred 	%p<8>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<49>;
	.reg .f64 	%fd<135>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd12;
	}
	shr.u32 	%r47, %r46, 20;
	setp.ne.s32	%p1, %r47, 0;
	@%p1 bra 	BB13_2;

	mul.f64 	%fd13, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd13;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r45, %temp}, %fd13;
	}
	shr.u32 	%r16, %r46, 20;
	add.s32 	%r47, %r16, -54;

BB13_2:
	add.s32 	%r48, %r47, -1023;
	and.b32  	%r17, %r46, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd133, {%r45, %r18};
	setp.lt.u32	%p2, %r18, 1073127583;
	@%p2 bra 	BB13_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd133;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd133;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd133, {%r19, %r21};
	add.s32 	%r48, %r47, -1022;

BB13_4:
	add.f64 	%fd15, %fd133, 0d3FF0000000000000;
	// inline asm
	rcp.approx.ftz.f64 %fd14,%fd15;
	// inline asm
	neg.f64 	%fd16, %fd15;
	mov.f64 	%fd17, 0d3FF0000000000000;
	fma.rn.f64 	%fd18, %fd16, %fd14, %fd17;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd14, %fd14;
	add.f64 	%fd21, %fd133, 0dBFF0000000000000;
	mul.f64 	%fd22, %fd21, %fd20;
	fma.rn.f64 	%fd23, %fd21, %fd20, %fd22;
	mul.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd26, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F6249249242B910;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F89999999999DFB;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	sub.f64 	%fd38, %fd21, %fd23;
	add.f64 	%fd39, %fd38, %fd38;
	neg.f64 	%fd40, %fd23;
	fma.rn.f64 	%fd41, %fd40, %fd21, %fd39;
	mul.f64 	%fd42, %fd20, %fd41;
	fma.rn.f64 	%fd43, %fd24, %fd37, 0d3FB5555555555555;
	mov.f64 	%fd44, 0d3FB5555555555555;
	sub.f64 	%fd45, %fd44, %fd43;
	fma.rn.f64 	%fd46, %fd24, %fd37, %fd45;
	add.f64 	%fd47, %fd46, 0d0000000000000000;
	add.f64 	%fd48, %fd47, 0dBC46A4CB00B9E7B0;
	add.f64 	%fd49, %fd43, %fd48;
	sub.f64 	%fd50, %fd43, %fd49;
	add.f64 	%fd51, %fd48, %fd50;
	mul.rn.f64 	%fd52, %fd23, %fd23;
	neg.f64 	%fd53, %fd52;
	fma.rn.f64 	%fd54, %fd23, %fd23, %fd53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd42;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd42;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd55, {%r22, %r24};
	fma.rn.f64 	%fd56, %fd23, %fd55, %fd54;
	mul.rn.f64 	%fd57, %fd52, %fd23;
	neg.f64 	%fd58, %fd57;
	fma.rn.f64 	%fd59, %fd52, %fd23, %fd58;
	fma.rn.f64 	%fd60, %fd52, %fd42, %fd59;
	fma.rn.f64 	%fd61, %fd56, %fd23, %fd60;
	mul.rn.f64 	%fd62, %fd49, %fd57;
	neg.f64 	%fd63, %fd62;
	fma.rn.f64 	%fd64, %fd49, %fd57, %fd63;
	fma.rn.f64 	%fd65, %fd49, %fd61, %fd64;
	fma.rn.f64 	%fd66, %fd51, %fd57, %fd65;
	add.f64 	%fd67, %fd62, %fd66;
	sub.f64 	%fd68, %fd62, %fd67;
	add.f64 	%fd69, %fd66, %fd68;
	add.f64 	%fd70, %fd23, %fd67;
	sub.f64 	%fd71, %fd23, %fd70;
	add.f64 	%fd72, %fd67, %fd71;
	add.f64 	%fd73, %fd69, %fd72;
	add.f64 	%fd74, %fd42, %fd73;
	add.f64 	%fd75, %fd70, %fd74;
	sub.f64 	%fd76, %fd70, %fd75;
	add.f64 	%fd77, %fd74, %fd76;
	xor.b32  	%r25, %r48, -2147483648;
	mov.u32 	%r26, 1127219200;
	mov.b64 	%fd78, {%r25, %r26};
	mov.u32 	%r27, -2147483648;
	mov.b64 	%fd79, {%r27, %r26};
	sub.f64 	%fd80, %fd78, %fd79;
	mov.f64 	%fd81, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd82, %fd80, %fd81, %fd75;
	neg.f64 	%fd83, %fd80;
	fma.rn.f64 	%fd84, %fd83, %fd81, %fd82;
	sub.f64 	%fd85, %fd84, %fd75;
	sub.f64 	%fd86, %fd77, %fd85;
	mov.f64 	%fd87, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd88, %fd80, %fd87, %fd86;
	add.f64 	%fd89, %fd82, %fd88;
	sub.f64 	%fd90, %fd82, %fd89;
	add.f64 	%fd91, %fd88, %fd90;
	mov.f64 	%fd92, 0d4010000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd92;
	}
	add.s32 	%r29, %r28, %r28;
	setp.gt.u32	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd92;
	}
	mov.b64 	%fd93, {%r32, %r31};
	mul.rn.f64 	%fd94, %fd89, %fd93;
	neg.f64 	%fd95, %fd94;
	fma.rn.f64 	%fd96, %fd89, %fd93, %fd95;
	fma.rn.f64 	%fd97, %fd91, %fd93, %fd96;
	add.f64 	%fd4, %fd94, %fd97;
	sub.f64 	%fd98, %fd94, %fd4;
	add.f64 	%fd5, %fd97, %fd98;
	mov.f64 	%fd99, 0d4338000000000000;
	mov.f64 	%fd100, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd101, %fd4, %fd100, %fd99;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd101;
	}
	mov.f64 	%fd102, 0dC338000000000000;
	add.rn.f64 	%fd103, %fd101, %fd102;
	mov.f64 	%fd104, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd105, %fd103, %fd104, %fd4;
	mov.f64 	%fd106, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd107, %fd103, %fd106, %fd105;
	mov.f64 	%fd108, 0d3E928AF3FCA213EA;
	mov.f64 	%fd109, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd110, %fd109, %fd107, %fd108;
	mov.f64 	%fd111, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd112, %fd110, %fd107, %fd111;
	mov.f64 	%fd113, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd114, %fd112, %fd107, %fd113;
	mov.f64 	%fd115, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd116, %fd114, %fd107, %fd115;
	mov.f64 	%fd117, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd118, %fd116, %fd107, %fd117;
	mov.f64 	%fd119, 0d3F81111111122322;
	fma.rn.f64 	%fd120, %fd118, %fd107, %fd119;
	mov.f64 	%fd121, 0d3FA55555555502A1;
	fma.rn.f64 	%fd122, %fd120, %fd107, %fd121;
	mov.f64 	%fd123, 0d3FC5555555555511;
	fma.rn.f64 	%fd124, %fd122, %fd107, %fd123;
	mov.f64 	%fd125, 0d3FE000000000000B;
	fma.rn.f64 	%fd126, %fd124, %fd107, %fd125;
	fma.rn.f64 	%fd127, %fd126, %fd107, %fd17;
	fma.rn.f64 	%fd128, %fd127, %fd107, %fd17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd128;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd128;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd134, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	 %f2, %r35;
	abs.ftz.f32 	%f1, %f2;
	setp.lt.ftz.f32	%p4, %f1, 0f4086232B;
	@%p4 bra 	BB13_7;

	setp.lt.f64	%p5, %fd4, 0d0000000000000000;
	add.f64 	%fd129, %fd4, 0d7FF0000000000000;
	selp.f64	%fd134, 0d0000000000000000, %fd129, %p5;
	setp.geu.ftz.f32	%p6, %f1, 0f40874800;
	@%p6 bra 	BB13_7;

	shr.u32 	%r36, %r13, 31;
	add.s32 	%r37, %r13, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r39, %r15;
	mov.b64 	%fd130, {%r14, %r40};
	sub.s32 	%r41, %r13, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd131, {%r44, %r43};
	mul.f64 	%fd134, %fd130, %fd131;

BB13_7:
	abs.f64 	%fd132, %fd134;
	setp.eq.f64	%p7, %fd132, 0d7FF0000000000000;
	@%p7 bra 	BB13_9;

	fma.rn.f64 	%fd134, %fd134, %fd5, %fd134;

BB13_9:
	st.param.f64	[func_retval0+0], %fd134;
	ret;
}


